{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762b7c46-3e9f-454f-b199-1368dfaa90b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-13T05:10:59.696127Z",
     "iopub.status.busy": "2026-01-13T05:10:59.695807Z",
     "iopub.status.idle": "2026-01-13T05:10:59.702585Z",
     "shell.execute_reply": "2026-01-13T05:10:59.700838Z",
     "shell.execute_reply.started": "2026-01-13T05:10:59.696100Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# https://docs.pytorch.org/docs/stable/notes/randomness.html\n",
    "RAND_SEED = 10241\n",
    "torch.manual_seed(RAND_SEED)\n",
    "random.seed(RAND_SEED)\n",
    "np.random.seed(RAND_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aba9e6-5fc7-4bcc-a416-8e2448fefa2b",
   "metadata": {},
   "source": [
    "# linear module impl\n",
    "\n",
    "**To be able to reproduce the same result across different executions, ensure we use specified seeds for places which entails use of randomness (e.g. initialization of model weights)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376d88a3-c511-4817-886f-7a6e8e765454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:50:07.148231Z",
     "iopub.status.busy": "2026-01-03T19:50:07.132647Z",
     "iopub.status.idle": "2026-01-03T19:50:10.160910Z",
     "shell.execute_reply": "2026-01-03T19:50:10.159641Z",
     "shell.execute_reply.started": "2026-01-03T19:50:07.146661Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import einsum\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, device: torch.device | None = None, dtype: torch.dtype =None) -> None:\n",
    "        super().__init__()\n",
    "        std = (2 / (in_features + out_features)) ** 0.5\n",
    "        self.w = nn.Parameter(nn.init.trunc_normal_(torch.empty(out_features, in_features, device=device, dtype=dtype), mean=0, std=std, a=-3*std, b=3*std))\n",
    "        print(self.w.device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        #return einsum(x, self.w, '... d_in , d_out d_in -> ... d_out')\n",
    "        return x @ self.w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "249bfb7a-90e7-4794-aa16-7cfb40b74321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T17:09:39.345914Z",
     "iopub.status.busy": "2026-01-03T17:09:39.345604Z",
     "iopub.status.idle": "2026-01-03T17:09:39.441938Z",
     "shell.execute_reply": "2026-01-03T17:09:39.440897Z",
     "shell.execute_reply.started": "2026-01-03T17:09:39.345890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1795, -0.2127],\n",
       "        [ 1.8593, -2.1613]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lxf = Linear(5, 2, device='cpu', dtype=torch.float32)\n",
    "\n",
    "x = torch.randn(2, 5, device='cpu')\n",
    "lxf.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fffea247-d4bc-444d-b1b9-53b58f770e52",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-03T07:42:14.909805Z",
     "iopub.status.busy": "2026-01-03T07:42:14.909495Z",
     "iopub.status.idle": "2026-01-03T07:42:14.920822Z",
     "shell.execute_reply": "2026-01-03T07:42:14.919038Z",
     "shell.execute_reply.started": "2026-01-03T07:42:14.909781Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function empty in module torch:\n",
      "\n",
      "empty(...)\n",
      "    empty(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False, memory_format=torch.contiguous_format) -> Tensor\n",
      "\n",
      "    Returns a tensor filled with uninitialized data. The shape of the tensor is\n",
      "    defined by the variable argument :attr:`size`.\n",
      "\n",
      "    .. note::\n",
      "        If :func:`torch.use_deterministic_algorithms()` and\n",
      "        :attr:`torch.utils.deterministic.fill_uninitialized_memory` are both set to\n",
      "        ``True``, the output tensor is initialized to prevent any possible\n",
      "        nondeterministic behavior from using the data as an input to an operation.\n",
      "        Floating point and complex tensors are filled with NaN, and integer tensors\n",
      "        are filled with the maximum value.\n",
      "\n",
      "    Args:\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "            Can be a variable number of arguments or a collection like a list or tuple.\n",
      "\n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_dtype`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_device`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "        pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "            the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "        memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "            returned Tensor. Default: ``torch.contiguous_format``.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.empty((2,3), dtype=torch.int64)\n",
      "        tensor([[ 9.4064e+13,  2.8000e+01,  9.3493e+13],\n",
      "                [ 7.5751e+18,  7.1428e+18,  7.5955e+18]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7674a6-440b-470b-8bdf-16dbf0ef635e",
   "metadata": {},
   "source": [
    "# Embedding layer impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e4e70e4-da4c-4830-a6e7-5e8454116733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T16:56:20.080008Z",
     "iopub.status.busy": "2026-01-05T16:56:20.079508Z",
     "iopub.status.idle": "2026-01-05T16:56:20.090809Z",
     "shell.execute_reply": "2026-01-05T16:56:20.088978Z",
     "shell.execute_reply.started": "2026-01-05T16:56:20.079964Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import reduce\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "        num_embeddings: int,\n",
    "        embedding_dim: int,\n",
    "        device: torch.device | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    ") -> None:\n",
    "        '''\n",
    "        num_embeddings: Vocabulary size\n",
    "        embedding_dim: Dimension of the embedding vectors\n",
    "        device: Device to store model parameters on\n",
    "        dtype: Model parameter datatype\n",
    "\n",
    "        See https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Parameter(nn.init.trunc_normal_(\n",
    "            torch.empty(num_embeddings, embedding_dim, dtype=dtype), mean=0, std=1, a=-3, b=3))\n",
    "        \n",
    "    def forward(self, token_ids: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        token_ids: A tensor of long type of shape (batch, seq_len)\n",
    "        \n",
    "        Spec:\n",
    "        Embedding layer serves as a mapping from individual token (identified\n",
    "        by its id) to corresponding embedding vector (of size `embedding_dim`)\n",
    "\n",
    "        So looking up embedding vector by given token id, assemble the found\n",
    "        vectors into a matrix then return is what embedding layer needs to do.\n",
    "\n",
    "        The resulting matrix will be of shape (batch, seq_len, embedding_dim)\n",
    "\n",
    "        To construct this matrix in imperative, non-linear algebra manner:\n",
    "            For each seq in batch:\n",
    "                For each token in seq:\n",
    "                    Get vector at self.embedding[token's ID] and add it to\n",
    "                        resulting matrix\n",
    "\n",
    "        The goal is to do this in pytorch-idiomatic, linear algebra way.\n",
    "\n",
    "        Use advanced indexing:\n",
    "        - https://numpy.org/doc/stable/user/basics.indexing.html\n",
    "        - https://numpy.org/neps/nep-0021-advanced-indexing.html\n",
    "        - https://blog.ezyang.com/2019/05/pytorch-internals/\n",
    "        '''\n",
    "        return self.embedding[token_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99f7525c-a3f7-483c-9547-534c59b6f621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T20:30:28.858248Z",
     "iopub.status.busy": "2026-01-03T20:30:28.854301Z",
     "iopub.status.idle": "2026-01-03T20:30:28.928724Z",
     "shell.execute_reply": "2026-01-03T20:30:28.924580Z",
     "shell.execute_reply.started": "2026-01-03T20:30:28.858138Z"
    }
   },
   "outputs": [],
   "source": [
    "token_seq_batch = torch.randint(low=0, high=10, size=(2, 3), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44d8b449-adc9-4a57-b74d-a534b206a535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T20:30:29.044923Z",
     "iopub.status.busy": "2026-01-03T20:30:29.044522Z",
     "iopub.status.idle": "2026-01-03T20:30:29.097093Z",
     "shell.execute_reply": "2026-01-03T20:30:29.093941Z",
     "shell.execute_reply.started": "2026-01-03T20:30:29.044899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 9, 2],\n",
       "        [2, 1, 6]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_seq_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ca82fdd-7cf3-44b7-8356-0a24667ba1bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T16:56:26.055118Z",
     "iopub.status.busy": "2026-01-05T16:56:26.053872Z",
     "iopub.status.idle": "2026-01-05T16:56:26.108723Z",
     "shell.execute_reply": "2026-01-05T16:56:26.107215Z",
     "shell.execute_reply.started": "2026-01-05T16:56:26.055072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6658,  0.0909,  0.4032],\n",
       "        [-1.3488, -0.3029,  0.6607],\n",
       "        [-0.5142, -0.0462, -0.1464],\n",
       "        [-0.3757,  0.7217, -0.0690],\n",
       "        [-1.1029, -0.4012,  0.5654],\n",
       "        [ 0.9065,  1.3091, -1.2292],\n",
       "        [-1.2851, -0.8448, -0.1809],\n",
       "        [-1.6742,  0.4734,  0.3509],\n",
       "        [-1.4873,  1.9627, -0.0351],\n",
       "        [ 0.3765,  0.0167, -1.7541]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size, embedding_dim = 10, 3\n",
    "toy_embeddings = nn.init.trunc_normal_(torch.empty(vocab_size, embedding_dim), mean=0, std=1, a=-3, b=3)\n",
    "toy_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e522fec-bc3b-4a87-8b15-866f030a9ea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T20:31:43.810855Z",
     "iopub.status.busy": "2026-01-03T20:31:43.810474Z",
     "iopub.status.idle": "2026-01-03T20:31:43.839473Z",
     "shell.execute_reply": "2026-01-03T20:31:43.838549Z",
     "shell.execute_reply.started": "2026-01-03T20:31:43.810825Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after: tensor([[[-0.5142, -0.0462, -0.1464],\n",
      "         [ 0.3765,  0.0167, -1.7541],\n",
      "         [-0.5142, -0.0462, -0.1464]],\n",
      "\n",
      "        [[-0.5142, -0.0462, -0.1464],\n",
      "         [-1.3488, -0.3029,  0.6607],\n",
      "         [-1.2851, -0.8448, -0.1809]]])\n"
     ]
    }
   ],
   "source": [
    "#token_to_embeddings = torch.empty(2, 3, 3)\n",
    "#print(f'initial: {token_to_embeddings}')\n",
    "\n",
    "token_to_embeddings = toy_embeddings[token_seq_batch]\n",
    "\n",
    "print(f'after: {token_to_embeddings}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd29c31c-4855-4752-9559-62320460f8f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T20:41:20.284898Z",
     "iopub.status.busy": "2026-01-03T20:41:20.284588Z",
     "iopub.status.idle": "2026-01-03T20:41:20.292309Z",
     "shell.execute_reply": "2026-01-03T20:41:20.291041Z",
     "shell.execute_reply.started": "2026-01-03T20:41:20.284874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_embeddings.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4a084-293f-44c5-b6c6-a961ecd99d8f",
   "metadata": {},
   "source": [
    "# Pre-norm transformer block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077268a-3993-4e54-9734-477d2aacefb1",
   "metadata": {},
   "source": [
    "## Root Mean Square Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "282dd702-a703-4656-b601-af710c4f7116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T17:35:58.680257Z",
     "iopub.status.busy": "2026-01-05T17:35:58.672442Z",
     "iopub.status.idle": "2026-01-05T17:35:58.799328Z",
     "shell.execute_reply": "2026-01-05T17:35:58.793577Z",
     "shell.execute_reply.started": "2026-01-05T17:35:58.678837Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import reduce, rearrange\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    '''Root Mean Square normalization block.\n",
    "\n",
    "    \n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        device: torch.device | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    ") -> None:\n",
    "        super().__init__()\n",
    "        self.gains = nn.Parameter(torch.ones(d_model, dtype=dtype, device=device))\n",
    "        # HYPERPARAM\n",
    "        self.e = 1e-5\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        x in shape (batch_size, sequence_length, d_model)\n",
    "        '''\n",
    "        in_dtype = x.dtype\n",
    "        # Q: shall we fix the dtype of model params (gains) to float32?\n",
    "        x = x.to(torch.float32)\n",
    "        d_model_size = x.shape[-1]\n",
    "        # Reduce along x's final dimension of size d_model in square sum\n",
    "        rms = torch.sqrt(reduce(torch.square(x) , 'b s d_model -> b s', reduction='sum') / d_model_size + self.e)\n",
    "        # For element-wise division to work we need to satisfy the broadcasting semantics\n",
    "        # Here rms is in shape (b, s) while the dividend (number to be divided) in shape (b, s, d_model)\n",
    "        # Thus adjust rms to shape (b, s, 1) for broadcasting to work\n",
    "        rms = rearrange(rms, 'b s -> b s 1')\n",
    "        #print(f'rms in shape {rms.shape}: {rms}')\n",
    "        #print(f'prod in shape {prod.shape}: {prod}')\n",
    "        res = x * self.gains / rms\n",
    "        return res.to(in_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de1bf8db-0f28-45a4-9183-db19d1559ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T17:35:58.832959Z",
     "iopub.status.busy": "2026-01-05T17:35:58.832622Z",
     "iopub.status.idle": "2026-01-05T17:35:59.142613Z",
     "shell.execute_reply": "2026-01-05T17:35:59.141148Z",
     "shell.execute_reply.started": "2026-01-05T17:35:58.832939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2126,  0.7276],\n",
       "         [ 0.6323,  1.2647],\n",
       "         [ 0.2000,  1.4000]],\n",
       "\n",
       "        [[ 1.3719,  0.3430],\n",
       "         [ 1.2647,  0.6323],\n",
       "         [ 1.4000,  0.2000]]], device='mps:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='mps'\n",
    "d_model = 2\n",
    "m = RMSNorm(d_model, device=device)\n",
    "\n",
    "m.forward(torch.tensor([[[-0.5, 0.3], [0.1, 0.2], [0.1, 0.7]], [[0.4, 0.1], [0.2, 0.1], [0.7, 0.1]]], device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f5fa8b5-d4c9-4c61-aba6-eda310f410c8",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-05T07:55:14.866094Z",
     "iopub.status.busy": "2026-01-05T07:55:14.865776Z",
     "iopub.status.idle": "2026-01-05T07:55:14.872243Z",
     "shell.execute_reply": "2026-01-05T07:55:14.871093Z",
     "shell.execute_reply.started": "2026-01-05T07:55:14.866068Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Help on built-in function element_size:\n",
      "\n",
      "element_size(...) method of torch.Tensor instance\n",
      "    element_size() -> int\n",
      "\n",
      "    Returns the size in bytes of an individual element.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.tensor([]).element_size()\n",
      "        4\n",
      "        >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "        1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(2, 3)\n",
    "print(t.element_size())\n",
    "help(t.element_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97ba7ed3-c2bf-4ca3-bee1-31fa9e6d6cab",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-05T07:55:20.791201Z",
     "iopub.status.busy": "2026-01-05T07:55:20.790911Z",
     "iopub.status.idle": "2026-01-05T07:55:20.801054Z",
     "shell.execute_reply": "2026-01-05T07:55:20.799389Z",
     "shell.execute_reply.started": "2026-01-05T07:55:20.791178Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf902ad-f4d1-4ec8-9060-98d77073938a",
   "metadata": {},
   "source": [
    "## Position-Wise Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbeaf4ce-d395-408c-befa-d18a7a639323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T18:25:01.783860Z",
     "iopub.status.busy": "2026-01-05T18:25:01.783535Z",
     "iopub.status.idle": "2026-01-05T18:25:01.797910Z",
     "shell.execute_reply": "2026-01-05T18:25:01.796454Z",
     "shell.execute_reply.started": "2026-01-05T18:25:01.783833Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import einsum\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    '''Position-Wise Feed-Forward Network\n",
    "\n",
    "    \n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        device: torch.device | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    ") -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        # Per assignment recommendation, get the multiple of 64 closest to 8/3 x d_model\n",
    "        d_ff = max(round(8 * d_model / 3 / 64), 1) * 64\n",
    "        print(f'Computed feed forward network dimension size = {d_ff}')\n",
    "        self.w1 = nn.Parameter(nn.init.trunc_normal_(\n",
    "            torch.empty(d_ff, d_model, dtype=dtype, device=device), mean=0, std=1, a=-3, b=3))\n",
    "        self.w3 = nn.Parameter(nn.init.trunc_normal_(\n",
    "            torch.empty(d_ff, d_model, dtype=dtype, device=device), mean=0, std=1, a=-3, b=3))\n",
    "        self.w2 = nn.Parameter(nn.init.trunc_normal_(\n",
    "            torch.empty(d_model, d_ff, dtype=dtype, device=device), mean=0, std=1, a=-3, b=3))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Spec:\n",
    "\n",
    "        Different from math notation which is column-major, here we apply matrix operation in row-major manner.\n",
    "        '''\n",
    "        # x_w1 = x @ self.w1.T\n",
    "        x_w1 = einsum(x, self.w1, '... d_model, d_ff d_model -> ... d_ff')\n",
    "        x_w1_sigmoid = x_w1 * torch.sigmoid(x_w1)\n",
    "        x_w3 = einsum(x, self.w3, '... d_model, d_ff d_model -> ... d_ff')\n",
    "        return einsum((x_w1_sigmoid * x_w3), self.w2, '... d_ff, d_model d_ff -> ... d_model')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55cc84c5-0cc0-4257-8c96-e2813315e28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T18:10:30.595470Z",
     "iopub.status.busy": "2026-01-05T18:10:30.595159Z",
     "iopub.status.idle": "2026-01-05T18:10:30.619636Z",
     "shell.execute_reply": "2026-01-05T18:10:30.618618Z",
     "shell.execute_reply.started": "2026-01-05T18:10:30.595443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4000, 3.2000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float)\n",
    "t2 = torch.tensor([0.1,0.2,0.3])\n",
    "t1 @ t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae188d4e-5161-4cbc-b090-e737528d1a9c",
   "metadata": {},
   "source": [
    "## RoPE - Now it becomes crucial to understand and document the shape of each layer's input and output :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bcc6e3f6-20a6-4d54-bdbe-f3d183e39704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:58:57.677938Z",
     "iopub.status.busy": "2026-01-09T04:58:57.677487Z",
     "iopub.status.idle": "2026-01-09T04:58:57.847941Z",
     "shell.execute_reply": "2026-01-09T04:58:57.846538Z",
     "shell.execute_reply.started": "2026-01-09T04:58:57.677899Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, einsum\n",
    "from jaxtyping import Float\n",
    "\n",
    "\n",
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device=None) -> None:\n",
    "        \"\"\"\n",
    "        This module is used in transformer model component \"Causal Multi-Head Self-Attention w/ RoPE\"\n",
    "        Its input is the output of pre-norm layer, in shape (batch_size, seq_len, d_embedding)\n",
    "\n",
    "        This is how we model positions in a transformer, aka encoding position-specific\n",
    "        info into the transformer model.\n",
    "        See https://youtu.be/ptFiH_bHnJw?list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_&t=2007\n",
    "\n",
    "        This is to construct a mathematical tool to measure how \"far\" a pair of tokens\n",
    "        are away from each other, aka *relative* position b/w a pair of token.\n",
    "\n",
    "        The idea is to use the observation that *inner product of two vector is invariant\n",
    "        to arbitrary rotation* to represent our desired characteristic that token embedding\n",
    "        should be invariant to absolute position.\n",
    "\n",
    "        d_k: dimension of query and key vectors, = d_embedding\n",
    "        (Note it seems we assume d_k to be a even number)\n",
    "\n",
    "        max_seq_len: Maximum sequence length. Used only for caching pre-computed rotation\n",
    "        angle values. Not necessarily = seq_len\n",
    "\n",
    "        spec:\n",
    "        i: token position index (in a token sequence). IMO i in [0, max_seq_len)\n",
    "            Q: Does this index start from 0 or 1? Assignment handout doesn't tell. But\n",
    "            per my experience in math notation indexing starting from 1 seems prevailing\n",
    "            A: Per UT, i starts from 0 (UT will barf if we use 1-based index)\n",
    "\n",
    "        R: Matrix that contain pair-wise rotation matrix R_i, where i in [0, max_seq_len)\n",
    "            R_i is of shape (d_k, d_k), so R is of shape (max_seq_len, d_k, d_k) to\n",
    "            account for ALL token positions in a token sequence.\n",
    "\n",
    "        The constructor logic is to compute and cache R.\n",
    "\n",
    "        If we did this in sequential manner:\n",
    "        For i in [0, max_seq_len):\n",
    "            Compute R_i.\n",
    "            For k in [1, d_k/2]:\n",
    "                Compute rotation angle theta_i_k\n",
    "                    theta_i_k = (i+1) / (theta^((2k-2)/d_k))\n",
    "                Compute cos and sin value at theta_i_k, form 2x2 matrix block R_i_k\n",
    "                Stack the block diagonally into R_i\n",
    "            R[i] = R_i\n",
    "\n",
    "        TODO: More pytorch-idiomatic, parallelizable impl\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert d_k % 2 == 0, f\"{d_k} is not even number\"\n",
    "\n",
    "        token_positions = torch.arange(max_seq_len, device=device, dtype=dtype)\n",
    "        # k in [1, 2, 3, ..., d/2] -> 2k-2 in [0, 2, 4, ..., d-2]\n",
    "        inv_theta_exps = theta ** (-torch.arange(start=0, end=d_k, step=2, device=device, dtype=dtype) / d_k)\n",
    "        # angle matrix of shape (max_seq_len, d_k/2)\n",
    "        angles = token_positions[:, None] * inv_theta_exps[None, :]\n",
    "        # sin and cos of angles (max_seq_len, d_k/2)\n",
    "        sin, cos = torch.sin(angles), torch.cos(angles)\n",
    "        R = torch.empty(max_seq_len, d_k, d_k, dtype=dtype, device=device)\n",
    "        indices_on_diag = torch.arange(start=0, end=d_k, step=2, dtype=dtype, device=device)\n",
    "        R[:, indices_on_diag, indices_on_diag] = cos\n",
    "        R[:, indices_on_diag+1, indices_on_diag] = sin\n",
    "        R[:, indices_on_diag, indices_on_diag+1] = -sin\n",
    "        R[:, indices_on_diag+1, indices_on_diag+1] = cos\n",
    "\n",
    "        # R\n",
    "        self.register_buffer(\n",
    "            \"rotation_matrix\",\n",
    "            R,\n",
    "            persistent=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: tensor of shape (..., seq_len, d_k)\n",
    "        token_positions: a tensor of shape (..., seq_len) specifying the token\n",
    "            positions of x along the sequence dimension.\n",
    "        return: a tensor of the same shape as x.\n",
    "\n",
    "        Spec:\n",
    "        Identify the rotation matrices to use by given token position.\n",
    "            Do this w/ Pytorch's advanced indexing: R[token_positions] -> tensor of shape (..., seq_len, d_k, d_k)\n",
    "        Multiply a token's embedding vector of shape (d_k,) w/ the corresponding identified rotation matrix of shape (d_k, d_k)\n",
    "        \"\"\"\n",
    "        rotation_matrix_by_pos: Float[Tensor, \"... d_k d_k\"] = self.rotation_matrix[\n",
    "            token_positions\n",
    "        ]\n",
    "        # note in einsum notation we cannot use duplicated\n",
    "        return einsum(\n",
    "            x,\n",
    "            rotation_matrix_by_pos,\n",
    "            # NOTE again in implementation we have to use row-major order,\n",
    "            # aka token_embedding_vector @ R_i.T Otherwise the result will\n",
    "            # be incorrect.\n",
    "            \"... d_k_in, ... d_k_out d_k_in -> ... d_k_out\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "77a0ba35-40db-4112-83ae-3adb7fb69320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:42:42.394519Z",
     "iopub.status.busy": "2026-01-09T04:42:42.394178Z",
     "iopub.status.idle": "2026-01-09T04:42:42.981103Z",
     "shell.execute_reply": "2026-01-09T04:42:42.979920Z",
     "shell.execute_reply.started": "2026-01-09T04:42:42.394492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.7937, 0.6300],\n",
       "        [2.0000, 1.5874, 1.2599],\n",
       "        [3.0000, 2.3811, 1.8899]], device='mps:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = 4\n",
    "d_k=6\n",
    "theta = 2\n",
    "device, dtype = 'mps', torch.float32\n",
    "token_positions = torch.arange(max_seq_len, device=device, dtype=dtype)\n",
    "print(token_positions.shape)\n",
    "# k in [1, 2, 3, ..., d/2] -> 2k-2 in [0, 2, 4, ..., d-2]\n",
    "inv_theta_exps = theta ** (-torch.arange(start=0, end=d_k, step=2, device=device, dtype=dtype) / d_k)\n",
    "print(inv_theta_exps.shape)\n",
    "# angle matrix of shape (max_seq_len, d_k / 2)\n",
    "angles = token_positions[:, None] * inv_theta_exps[None, :]\n",
    "print(torch.equal(angles, token_positions[:, None] @ inv_theta_exps[None, :]))\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f7b89e1a-2045-4666-877a-eebf9839c45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:40:12.652519Z",
     "iopub.status.busy": "2026-01-09T04:40:12.652225Z",
     "iopub.status.idle": "2026-01-09T04:40:12.673615Z",
     "shell.execute_reply": "2026-01-09T04:40:12.672180Z",
     "shell.execute_reply.started": "2026-01-09T04:40:12.652496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]], device='mps:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(token_positions.unsqueeze(dim=1), token_positions[:, None])\n",
    "token_positions[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7855a289-b6f0-4e31-ba47-43b334f9a8a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:40:22.967050Z",
     "iopub.status.busy": "2026-01-09T04:40:22.966739Z",
     "iopub.status.idle": "2026-01-09T04:40:22.986559Z",
     "shell.execute_reply": "2026-01-09T04:40:22.985396Z",
     "shell.execute_reply.started": "2026-01-09T04:40:22.967024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7937, 0.6300]], device='mps:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(inv_theta_exps[None, :], inv_theta_exps.unsqueeze(dim=0))\n",
    "inv_theta_exps[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a2889caa-618d-4709-bf8c-9ab7a166ba43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:55:06.826054Z",
     "iopub.status.busy": "2026-01-09T04:55:06.825756Z",
     "iopub.status.idle": "2026-01-09T04:55:06.889530Z",
     "shell.execute_reply": "2026-01-09T04:55:06.888147Z",
     "shell.execute_reply.started": "2026-01-09T04:55:06.826030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.8415, 0.7130, 0.5891],\n",
      "        [0.9093, 0.9999, 0.9521],\n",
      "        [0.1411, 0.6893, 0.9495]], device='mps:0')\n",
      "tensor([[ 1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5403,  0.7012,  0.8081],\n",
      "        [-0.4161, -0.0166,  0.3059],\n",
      "        [-0.9900, -0.7245, -0.3137]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "sin, cos = torch.sin(angles), torch.cos(angles)\n",
    "print(sin)\n",
    "print(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a2c3643d-3a50-49f2-a421-b386f58e431b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T04:56:16.553413Z",
     "iopub.status.busy": "2026-01-09T04:56:16.553073Z",
     "iopub.status.idle": "2026-01-09T04:56:16.567273Z",
     "shell.execute_reply": "2026-01-09T04:56:16.565655Z",
     "shell.execute_reply.started": "2026-01-09T04:56:16.553385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "R = torch.zeros(max_seq_len, d_k, d_k, device='mps')\n",
    "idx = torch.arange(0, d_k, 2)\n",
    "print(idx)\n",
    "R[:, idx, idx] = cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "509d4e47-26e2-489c-a16c-7a01b716297f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T06:18:39.521293Z",
     "iopub.status.busy": "2026-01-09T06:18:39.520980Z",
     "iopub.status.idle": "2026-01-09T06:18:39.530496Z",
     "shell.execute_reply": "2026-01-09T06:18:39.529114Z",
     "shell.execute_reply.started": "2026-01-09T06:18:39.521268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]]]) torch.Size([2, 2, 5])\n",
      "tensor([[[[0.0000, 0.1000, 0.2000, 0.3000, 0.4000],\n",
      "          [0.5000, 0.6000, 0.7000, 0.8000, 0.9000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.1000, 1.2000, 1.3000, 1.4000],\n",
      "          [1.5000, 1.6000, 1.7000, 1.8000, 1.9000]]]]) torch.Size([2, 1, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "torch.manual_seed(43)\n",
    "t1 = torch.reshape(torch.arange(0, 20), (2, 2, 5))\n",
    "print(t1, t1.shape)\n",
    "t2 = rearrange(torch.arange(0, 2, step=0.1).reshape(2, 2, 5), 'b s d -> b 1 s d')\n",
    "print(t2, t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "78d1e701-0d73-4b82-89c1-6fd07e44cca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T16:33:31.017370Z",
     "iopub.status.busy": "2026-01-09T16:33:31.009522Z",
     "iopub.status.idle": "2026-01-09T16:33:31.114541Z",
     "shell.execute_reply": "2026-01-09T16:33:31.111573Z",
     "shell.execute_reply.started": "2026-01-09T16:33:31.016640Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000,  0.1000,  0.4000,  0.9000,  1.6000],\n",
       "           [ 2.5000,  3.6000,  4.9000,  6.4000,  8.1000]],\n",
       " \n",
       "          [[ 0.0000,  1.1000,  2.4000,  3.9000,  5.6000],\n",
       "           [ 7.5000,  9.6000, 11.9000, 14.4000, 17.1000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0000,  1.1000,  2.4000,  3.9000,  5.6000],\n",
       "           [ 7.5000,  9.6000, 11.9000, 14.4000, 17.1000]],\n",
       " \n",
       "          [[10.0000, 12.1000, 14.4000, 16.9000, 19.6000],\n",
       "           [22.5000, 25.6000, 28.9000, 32.4000, 36.1000]]]]),\n",
       " torch.Size([2, 2, 2, 5]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The element-wise multiplication below uses broadcasting.\n",
    "# For how it works, see https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "t3 = t1 * t2\n",
    "t3, t3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351f416-68e4-49fc-a8a9-79ec8a1079ad",
   "metadata": {},
   "source": [
    "## Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6f961d59-c999-4d60-b897-1d05bdee8e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T17:41:23.868783Z",
     "iopub.status.busy": "2026-01-09T17:41:23.868445Z",
     "iopub.status.idle": "2026-01-09T17:41:23.874655Z",
     "shell.execute_reply": "2026-01-09T17:41:23.873226Z",
     "shell.execute_reply.started": "2026-01-09T17:41:23.868759Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def softmax(x: torch.Tensor, i: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x: Multi-dimensional tensor.\n",
    "    i: The i-th dimension of x (For now assume the index is 0-based)\n",
    "    return: Tensor of same shape as x, w/ values at i-th dimension turn into\n",
    "        normalized probabilities under softmax.\n",
    "\n",
    "    Can refer to the behavior of std pytorch lib softmax function.\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        -x.ndim <= i < x.ndim\n",
    "    ), f\"Given dimension index {i} not found in tensor of {x.ndim} dimensions\"\n",
    "    # Get the max values and corresponding indices on dimension i, plus keeping\n",
    "    # x's dimension around. This saves the extra move of creating a new\n",
    "    # dimensin in the resulting tensor (eg via tensor.unsqueeze(dim=i))\n",
    "    max_on_dim_i = x.max(dim=i, keepdim=True)\n",
    "    # softmax formula\n",
    "    # Subtract values on dimension i by the max values so that exp()\n",
    "    # of these values yields small values in (0, 1] for numerical stability\n",
    "    exp = torch.exp(x - max_on_dim_i.values)\n",
    "    exp_sum_on_dim_i = torch.sum(exp, dim=i, keepdim=True)\n",
    "    return exp / exp_sum_on_dim_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7a1482b-2a10-44b3-b521-5e032dc54189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T06:47:47.542321Z",
     "iopub.status.busy": "2026-01-08T06:47:47.538964Z",
     "iopub.status.idle": "2026-01-08T06:47:47.575109Z",
     "shell.execute_reply": "2026-01-08T06:47:47.573063Z",
     "shell.execute_reply.started": "2026-01-08T06:47:47.542221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.5397e-05, 1.7986e-02],\n",
      "         [3.0588e-07, 6.0337e-06],\n",
      "         [1.6701e-05, 9.8201e-01],\n",
      "         [9.9994e-01, 2.0241e-09]],\n",
      "\n",
      "        [[6.6767e-10, 9.5256e-01],\n",
      "         [2.9539e-04, 1.5909e-05],\n",
      "         [8.8054e-01, 4.7425e-02],\n",
      "         [1.1917e-01, 7.2228e-10]],\n",
      "\n",
      "        [[1.2202e-05, 1.2328e-04],\n",
      "         [6.6619e-04, 9.1090e-04],\n",
      "         [2.6876e-01, 9.9892e-01],\n",
      "         [7.3056e-01, 4.5351e-05]]])\n",
      "tensor([[1.0000, 1.0000],\n",
      "        [1.0000, 1.0000],\n",
      "        [1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "re = sm(torch.randint(0, 24, (3, 4, 2)).to(torch.float32), i=1)\n",
    "print(re)\n",
    "print(torch.sum(re[:, :, ::], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642668d-671b-406b-bf13-431655d91f91",
   "metadata": {},
   "source": [
    "### Observing the behavior of software function in std Pytorch lib provides clue of impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86b4cef0-16bb-43c8-b793-0d3453a6c70b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T06:05:18.053596Z",
     "iopub.status.busy": "2026-01-08T06:05:18.053302Z",
     "iopub.status.idle": "2026-01-08T06:05:18.062511Z",
     "shell.execute_reply": "2026-01-08T06:05:18.061336Z",
     "shell.execute_reply.started": "2026-01-08T06:05:18.053573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[14.,  6.],\n",
       "         [ 9., 13.],\n",
       "         [ 5., 17.],\n",
       "         [21., 20.]],\n",
       "\n",
       "        [[ 6., 19.],\n",
       "         [12., 11.],\n",
       "         [ 4., 12.],\n",
       "         [ 9.,  1.]],\n",
       "\n",
       "        [[10., 22.],\n",
       "         [13.,  3.],\n",
       "         [ 5.,  7.],\n",
       "         [22.,  3.]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0, 24, (3, 4, 2)).to(torch.float32)\n",
    "print(t.shape)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fab438f-ecfa-4a98-89c0-b92eaf292dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T06:22:40.520828Z",
     "iopub.status.busy": "2026-01-08T06:22:40.520423Z",
     "iopub.status.idle": "2026-01-08T06:22:40.529147Z",
     "shell.execute_reply": "2026-01-08T06:22:40.527670Z",
     "shell.execute_reply.started": "2026-01-08T06:22:40.520799Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -7., -14.],\n",
       "         [-12.,  -7.],\n",
       "         [-16.,  -3.],\n",
       "         [  0.,   0.]],\n",
       "\n",
       "        [[ -6.,   0.],\n",
       "         [  0.,  -8.],\n",
       "         [ -8.,  -7.],\n",
       "         [ -3., -18.]],\n",
       "\n",
       "        [[-12.,   0.],\n",
       "         [ -9., -19.],\n",
       "         [-17., -15.],\n",
       "         [  0., -19.]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_d_2 = t.max(dim=1)\n",
    "t - max_d_2.values.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ace7f006-9505-4fbe-ada2-160d2ad3bc8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T06:23:35.197745Z",
     "iopub.status.busy": "2026-01-08T06:23:35.197409Z",
     "iopub.status.idle": "2026-01-08T06:23:35.210892Z",
     "shell.execute_reply": "2026-01-08T06:23:35.209028Z",
     "shell.execute_reply.started": "2026-01-08T06:23:35.197720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7000, 0.3000],\n",
       "         [0.4091, 0.5909],\n",
       "         [0.2273, 0.7727],\n",
       "         [0.5122, 0.4878]],\n",
       "\n",
       "        [[0.2400, 0.7600],\n",
       "         [0.5217, 0.4783],\n",
       "         [0.2500, 0.7500],\n",
       "         [0.9000, 0.1000]],\n",
       "\n",
       "        [[0.3125, 0.6875],\n",
       "         [0.8125, 0.1875],\n",
       "         [0.4167, 0.5833],\n",
       "         [0.8800, 0.1200]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t / torch.sum(t, dim=2).unsqueeze(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df4d6217-56a7-4859-bec4-7f34cab13482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T05:56:59.353355Z",
     "iopub.status.busy": "2026-01-08T05:56:59.353035Z",
     "iopub.status.idle": "2026-01-08T05:56:59.361266Z",
     "shell.execute_reply": "2026-01-08T05:56:59.359598Z",
     "shell.execute_reply.started": "2026-01-08T05:56:59.353329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9.9995e-01, 4.5398e-05],\n",
      "         [7.3106e-01, 2.6894e-01],\n",
      "         [1.2339e-04, 9.9988e-01],\n",
      "         [5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "        [[1.7986e-02, 9.8201e-01],\n",
      "         [1.0000e+00, 2.2603e-06],\n",
      "         [6.6929e-03, 9.9331e-01],\n",
      "         [5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "        [[6.1442e-06, 9.9999e-01],\n",
      "         [4.7426e-02, 9.5257e-01],\n",
      "         [9.9988e-01, 1.2339e-04],\n",
      "         [4.5398e-05, 9.9995e-01]]])\n",
      "tensor([9.9995e-01, 4.5398e-05])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "t_sm = torch.softmax(t, dim=2)\n",
    "print(t_sm)\n",
    "softmaxed_unit = t_sm[0][0]\n",
    "print(softmaxed_unit)\n",
    "print(torch.sum(softmaxed_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5efeece-760a-452a-b11f-a2577f7ff733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T05:57:25.284267Z",
     "iopub.status.busy": "2026-01-08T05:57:25.283949Z",
     "iopub.status.idle": "2026-01-08T05:57:25.297124Z",
     "shell.execute_reply": "2026-01-08T05:57:25.295789Z",
     "shell.execute_reply.started": "2026-01-08T05:57:25.284242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.1850e-01, 5.4000e-06],\n",
      "         [5.8997e-03, 2.1785e-03],\n",
      "         [1.4624e-05, 1.1894e-01],\n",
      "         [8.7559e-01, 8.7887e-01]],\n",
      "\n",
      "        [[1.1243e-07, 6.1441e-06],\n",
      "         [9.1105e-04, 2.0611e-09],\n",
      "         [1.1243e-07, 1.6701e-05],\n",
      "         [9.9909e-01, 9.9998e-01]],\n",
      "\n",
      "        [[1.5225e-08, 3.3534e-04],\n",
      "         [1.1250e-07, 3.0579e-07],\n",
      "         [9.9966e-01, 1.6696e-05],\n",
      "         [3.3535e-04, 9.9965e-01]]])\n",
      "tensor([1.1850e-01, 5.8997e-03, 1.4624e-05, 8.7559e-01])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "t_sm = torch.softmax(t, dim=1)\n",
    "print(t_sm)\n",
    "softmaxed_unit = t_sm[0][:, 0]\n",
    "print(softmaxed_unit)\n",
    "print(torch.sum(softmaxed_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99613d3c-1ebf-4c72-8bf4-8eb0f6c4f2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T06:00:41.911392Z",
     "iopub.status.busy": "2026-01-08T06:00:41.911017Z",
     "iopub.status.idle": "2026-01-08T06:00:41.920314Z",
     "shell.execute_reply": "2026-01-08T06:00:41.918815Z",
     "shell.execute_reply.started": "2026-01-08T06:00:41.911362Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9.9995e-01, 3.2932e-04],\n",
      "         [1.1920e-01, 9.9326e-01],\n",
      "         [2.2603e-06, 9.8670e-01],\n",
      "         [1.7985e-02, 9.0747e-03]],\n",
      "\n",
      "        [[4.5398e-05, 1.7980e-02],\n",
      "         [8.8078e-01, 4.5094e-05],\n",
      "         [8.3153e-07, 6.6484e-03],\n",
      "         [9.8197e-01, 4.9546e-01]],\n",
      "\n",
      "        [[8.3149e-07, 9.8169e-01],\n",
      "         [1.4711e-05, 6.6925e-03],\n",
      "         [1.0000e+00, 6.6484e-03],\n",
      "         [4.4581e-05, 4.9546e-01]]])\n",
      "tensor([9.9995e-01, 4.5398e-05, 8.3149e-07])\n",
      "tensor(1.)\n",
      "tensor([0.9867, 0.0066, 0.0066])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "t_sm = torch.softmax(t, dim=0)\n",
    "print(t_sm)\n",
    "softmaxed_unit = t_sm[:, 0, 0]\n",
    "print(softmaxed_unit)\n",
    "print(torch.sum(softmaxed_unit))\n",
    "\n",
    "softmaxed_unit = t_sm[:, 2, 1]\n",
    "print(softmaxed_unit)\n",
    "print(torch.sum(softmaxed_unit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798cb9b-25da-4fab-b87c-d4cacfaf32f3",
   "metadata": {},
   "source": [
    "## Scaled Dot-Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1f2ca41c-9a93-41c8-ac59-f28896fe1355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T22:16:09.382342Z",
     "iopub.status.busy": "2026-01-10T22:16:09.377803Z",
     "iopub.status.idle": "2026-01-10T22:16:09.547566Z",
     "shell.execute_reply": "2026-01-10T22:16:09.544229Z",
     "shell.execute_reply.started": "2026-01-10T22:16:09.382281Z"
    }
   },
   "outputs": [],
   "source": [
    "from jaxtyping import Float, Bool\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "def scaled_dot_product_attention(\n",
    "    Q: Float[Tensor, '... queries d_k'],\n",
    "    K: Float[Tensor, '... keys d_k'],\n",
    "    V: Float[Tensor, '... values d_v'],\n",
    "    mask: Bool[Tensor, '... queries keys'] | None = None,\n",
    ") -> Float[Tensor, '... queries d_v']:\n",
    "    '''\n",
    "    Your implementation should handle keys and queries of shape\n",
    "    (batch_size, ..., seq_len, d_k) and values of shape\n",
    "    (batch_size, ..., seq_len, d_v), where ... represents any\n",
    "    number of other batch-like dimensions (if provided).\n",
    "    The implementation should return an output with the\n",
    "    shape (batch_size, ..., d_v).\n",
    "\n",
    "    Spec:\n",
    "    Compute K @ Q.T / sqrt(d_k), yielding a tensor of shape (... keys queries)\n",
    "    Apply mask to result above if given.\n",
    "    Apply softmax.\n",
    "    Matmul result above w/ V, aka V @ (result above).T\n",
    "    '''\n",
    "    d_k = K.shape[-1]\n",
    "    # (... queries keys)\n",
    "    presoftmax = Q @ K.T / (d_k ** 0.5)\n",
    "    if mask is not None:\n",
    "        # mask tensor serves as an index; For positions in index where mask value is false, we assign -inf so that the resulting exp value becomes 0.\n",
    "        presoftmax[~mask] = -float('inf')\n",
    "\n",
    "    softmaxed = softmax(presoftmax, dim=-1)\n",
    "    return softmaxed @ V\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d209514e-fb4d-48b8-b831-5387ef2b8968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T17:38:07.494042Z",
     "iopub.status.busy": "2026-01-09T17:38:07.493725Z",
     "iopub.status.idle": "2026-01-09T17:38:07.512552Z",
     "shell.execute_reply": "2026-01-09T17:38:07.510795Z",
     "shell.execute_reply.started": "2026-01-09T17:38:07.494010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 4., 0.],\n",
       "         [0., 5., 2.]]),\n",
       " tensor([[ True, False, False],\n",
       "         [False,  True,  True]]),\n",
       " tensor([[-inf, -inf, -inf],\n",
       "         [-inf, -inf, -inf]]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import repeat\n",
    "\n",
    "torch.manual_seed(36)\n",
    "t = torch.randint(0, 6, (2, 3)).to(torch.float32)\n",
    "mask = torch.tensor([[True, False, False], [False, True, True]])\n",
    "infs = repeat(torch.tensor([-float('inf')]), 'd -> a (b d)', a=2, b=3)\n",
    "t, mask, infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6274ade1-590b-4480-b09f-644718ab5e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T17:37:14.697632Z",
     "iopub.status.busy": "2026-01-09T17:37:14.697295Z",
     "iopub.status.idle": "2026-01-09T17:37:14.704302Z",
     "shell.execute_reply": "2026-01-09T17:37:14.703277Z",
     "shell.execute_reply.started": "2026-01-09T17:37:14.697606Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 2])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2cc4d6c1-6bfa-48b4-b298-4ecea42804de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T17:23:12.676929Z",
     "iopub.status.busy": "2026-01-09T17:23:12.676620Z",
     "iopub.status.idle": "2026-01-09T17:23:12.691196Z",
     "shell.execute_reply": "2026-01-09T17:23:12.689732Z",
     "shell.execute_reply.started": "2026-01-09T17:23:12.676905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 5]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a82b2504-da5b-42af-8936-0e18b4cf62ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T17:38:13.171587Z",
     "iopub.status.busy": "2026-01-09T17:38:13.171277Z",
     "iopub.status.idle": "2026-01-09T17:38:13.183439Z",
     "shell.execute_reply": "2026-01-09T17:38:13.181794Z",
     "shell.execute_reply.started": "2026-01-09T17:38:13.171562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., -inf, -inf],\n",
       "        [-inf, 5., 2.]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[~mask] = -float('inf')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6337c7de-d0df-4ab8-b619-19686da07e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T17:27:42.213639Z",
     "iopub.status.busy": "2026-01-09T17:27:42.213293Z",
     "iopub.status.idle": "2026-01-09T17:27:42.231442Z",
     "shell.execute_reply": "2026-01-09T17:27:42.230100Z",
     "shell.execute_reply.started": "2026-01-09T17:27:42.213614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor([-float('inf')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "777740c6-9f4a-48b2-99f7-d1df1e22aeef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:02:01.620272Z",
     "iopub.status.busy": "2026-01-16T18:02:01.619915Z",
     "iopub.status.idle": "2026-01-16T18:02:01.628387Z",
     "shell.execute_reply": "2026-01-16T18:02:01.627090Z",
     "shell.execute_reply.started": "2026-01-16T18:02:01.620245Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.5000,   1.4000,   2.3000,   3.2000,   4.1000],\n",
       "         [  1.4000,   5.0000,   8.6000,  12.2000,  15.8000],\n",
       "         [  2.3000,   8.6000,  14.9000,  21.2000,  27.5000],\n",
       "         [  3.2000,  12.2000,  21.2000,  30.2000,  39.2000]],\n",
       "\n",
       "        [[ 62.6000,  74.3000,  86.0000,  97.7000, 109.4000],\n",
       "         [ 77.0000,  91.4000, 105.8000, 120.2000, 134.6000],\n",
       "         [ 91.4000, 108.5000, 125.6000, 142.7000, 159.8000],\n",
       "         [105.8000, 125.6000, 145.4000, 165.2000, 185.0000]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(41)\n",
    "t1 = torch.arange(0, 2.4, 0.1).reshape(2, 4, 3).to(torch.float32)\n",
    "t2 = torch.arange(0, 30, 1).reshape(2, 5, 3).to(torch.float32)\n",
    "t1 @ t2.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8f2e61f-4ce0-4015-8531-ce1e524576f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:02:06.039404Z",
     "iopub.status.busy": "2026-01-16T18:02:06.039081Z",
     "iopub.status.idle": "2026-01-16T18:02:06.046218Z",
     "shell.execute_reply": "2026-01-16T18:02:06.045109Z",
     "shell.execute_reply.started": "2026-01-16T18:02:06.039379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  0.5000,   1.4000,   2.3000,   3.2000,   4.1000],\n",
       "          [  1.4000,   5.0000,   8.6000,  12.2000,  15.8000],\n",
       "          [  2.3000,   8.6000,  14.9000,  21.2000,  27.5000],\n",
       "          [  3.2000,  12.2000,  21.2000,  30.2000,  39.2000]],\n",
       " \n",
       "         [[ 62.6000,  74.3000,  86.0000,  97.7000, 109.4000],\n",
       "          [ 77.0000,  91.4000, 105.8000, 120.2000, 134.6000],\n",
       "          [ 91.4000, 108.5000, 125.6000, 142.7000, 159.8000],\n",
       "          [105.8000, 125.6000, 145.4000, 165.2000, 185.0000]]]),\n",
       " torch.Size([2, 4, 5]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re = t1 @ t2.transpose(-1, -2)\n",
    "re, re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b1b7b87-342d-453e-a4f5-1fa5c07a5981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T18:02:07.996842Z",
     "iopub.status.busy": "2026-01-16T18:02:07.996520Z",
     "iopub.status.idle": "2026-01-16T18:02:08.002963Z",
     "shell.execute_reply": "2026-01-16T18:02:08.001331Z",
     "shell.execute_reply.started": "2026-01-16T18:02:07.996816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re[..., 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd71227b-a6fd-4108-abdc-85983feccd37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T06:27:24.034948Z",
     "iopub.status.busy": "2026-01-17T06:27:24.034639Z",
     "iopub.status.idle": "2026-01-17T06:27:24.041246Z",
     "shell.execute_reply": "2026-01-17T06:27:24.039717Z",
     "shell.execute_reply.started": "2026-01-17T06:27:24.034919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function element_size:\n",
      "\n",
      "element_size(...) method of torch.Tensor instance\n",
      "    element_size() -> int\n",
      "\n",
      "    Returns the size in bytes of an individual element.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.tensor([]).element_size()\n",
      "        4\n",
      "        >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "        1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(re.element_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab1f6a78-3d03-4c46-9f42-334a351682ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T06:41:42.695677Z",
     "iopub.status.busy": "2026-01-17T06:41:42.695388Z",
     "iopub.status.idle": "2026-01-17T06:41:42.700822Z",
     "shell.execute_reply": "2026-01-17T06:41:42.699737Z",
     "shell.execute_reply.started": "2026-01-17T06:41:42.695653Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.int64.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "40a7d021-ee2c-4e01-9ad5-9a098dbd054a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T05:04:30.780192Z",
     "iopub.status.busy": "2026-01-10T05:04:30.779855Z",
     "iopub.status.idle": "2026-01-10T05:04:30.793308Z",
     "shell.execute_reply": "2026-01-10T05:04:30.792040Z",
     "shell.execute_reply.started": "2026-01-10T05:04:30.780164Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0],\n",
       "        [  2,  -6,  10,  -4],\n",
       "        [  4, -12,  20,  -8]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import einsum\n",
    "\n",
    "t1, t2 = torch.tensor([0, 2, 4]), torch.tensor([1, -3, 5, -2])\n",
    "# = column vector of shape (3,) @ row vector (1, 4) = matrix of shape (3, 4)\n",
    "einsum(t1, t2, 'i, j -> i j')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b62be-2afe-4cb1-a78e-0d67832223ec",
   "metadata": {},
   "source": [
    "## Multi-head self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53662ffe-d91d-433b-89ee-54a5a950815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float, Bool\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "\n",
    "class MultiheadSelfAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        num_heads: int,\n",
    "        theta: float | None = None,\n",
    "        max_seq_len = int | None = None,\n",
    "        device: torch.device | None = None,\n",
    "        dtype: torch.dtype | None = None,\n",
    "    ) -> None:\n",
    "        '''\n",
    "        d_model: Dimensionality of the Transformer block inputs.\n",
    "            == embedding vector dimension size d_embedding.\n",
    "        num_heads: Number of heads to use in multi-head self-attention.\n",
    "        theta, max_seq_len: Parameters for initializing RoPE layer.\n",
    "\n",
    "        Folllowing Vaswani et al. [2017], set d_k = d_v = d_model / h.\n",
    "\n",
    "        TODO:\n",
    "        - Any initialization for causal masking?\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Initialize following linear weights per assignment section 3.4.1\n",
    "        # W_Q, W_K, W_V all in shape (d_model (=h x d_k or h x d_v), d_model)\n",
    "        # W_O in shape (d_model, d_model (=h x d_v))\n",
    "        std = d_model ** -0.5\n",
    "        self.W_Q = nn.Parameter(nn.init.trunc_normal_(torch.empty(d_model, d_model, device=device, dtype=dtype), mean=0, std=std, a=-3*std, b=3*std))\n",
    "        self.W_K = nn.Parameter(nn.init.trunc_normal_(torch.empty(d_model, d_model, device=device, dtype=dtype), mean=0, std=std, a=-3*std, b=3*std))\n",
    "        self.W_V = nn.Parameter(nn.init.trunc_normal_(torch.empty(d_model, d_model, device=device, dtype=dtype), mean=0, std=std, a=-3*std, b=3*std))\n",
    "        self.W_O = nn.Parameter(nn.init.trunc_normal_(torch.empty(d_model, d_model, device=device, dtype=dtype), mean=0, std=std, a=-3*std, b=3*std))\n",
    "        self.num_heads = num_heads\n",
    "        if theta is not None and max_seq_len is not None:\n",
    "            self.rope = RotaryPositionalEmbedding(theta, d_k=d_model, max_seq_len=max_seq_len, device=device, dtype=dtype)\n",
    "        \n",
    "    def forward(self, x: Float[Tensor, '... seq_len d_model']) -> torch.Tensor:\n",
    "        '''\n",
    "        Spec:\n",
    "        (NOTE we use impl notation below instead of math notation appeared in assignment handout)\n",
    "        \n",
    "        Build the attention logic bottom-up, w/ naive approach first.\n",
    "            The smallest logic unit is Attention(Q_i, K_i, V_i), where i in [0, num_heads)\n",
    "            Q_i = x @ (the i-th out of h slices of W_Q.T). The shape of W_Q.T is (d_model, h x d_k)\n",
    "            \n",
    "            Similar paradigm applies to K_i and V_i. Reading the original transformer paper I believe\n",
    "            the dimension on which slicing applies is the dimension of embedding vector.\n",
    "            \n",
    "            (Slicing this way makes sense, cuz suppose we sliced on the dimension of token sequence,\n",
    "            then when processing a token in a particular slice, how can the model attend to tokens\n",
    "            which run *before* this token? No way, cuz embeddings of such predecessor tokens likely\n",
    "            would have been in different slices -- a contradiction and dead end)\n",
    "\n",
    "        Dimension along which concatenation of head_1, head_2, ... head_h is the last dim\n",
    "            and the size of resulting dimension is d_model\n",
    "\n",
    "        IMO we only need to slice right before calling scaled_dot_product_attention fn.\n",
    "        Ensure correctness first before jumping to optimization.\n",
    "\n",
    "        TODO:\n",
    "            - Masking to attend only predecessor tokens\n",
    "        TODO: For efficient tensor ops, we can lump W_Q, W_K, W_V into a single large tensor instead of separating them.\n",
    "        '''\n",
    "        # Reshape tensors so that on the last dimension resides per-head values subject to application of attention.\n",
    "        # This way we avoid the hassle and inefficiency of for i in num_heads do Attention(Q_i, K_i, V_i) :D\n",
    "        # Note d_head x d_embedding_per_head = d_embedding (aka d_model)\n",
    "        Q_all_h = rearrange(x @ self.W_Q.T, '... d_seq (d_head d_embedding_per_head) -> ... d_head d_seq d_embedding_per_head', d_head=self.num_heads)\n",
    "        K_all_h = rearrange(x @ self.W_K.T, '... d_seq (d_head d_embedding_per_head) -> ... d_head d_seq d_embedding_per_head', d_head=self.num_heads)\n",
    "        # Apply RoPE to query and key before applying attention\n",
    "        if hasattr(self, 'rope'):\n",
    "            Q_all_h = self.rope.forward(Q_all_h)\n",
    "            K_all_h = self.rope.forward(K_all_h)\n",
    "        V_all_h = rearrange(x @ self.W_V.T, '... d_seq (d_head d_embedding_per_head) -> ... d_head d_seq d_embedding_per_head', d_head=self.num_heads)\n",
    "        # Tensor for causal masking\n",
    "        # We shall directly use the existing masking logic in scaled_dot_product_attention; The problem is now reduced to creation of a mask tensor.\n",
    "        # By definition, the mask should apply along the dimension of token sequence.\n",
    "        # Prompting ChatGPT about the meaning of Q and K matrix, whose result of matmul over dimension (d_embedding_per_head)\n",
    "        # (shape involved: (d_q x d_embedding_per_head) @ (d_embedding_per_head x d_k)) is\n",
    "        # the input of masking in scaled dot product attention function, ChatGPT's response\n",
    "        # claims that a row in Q, corresponding to a token in sequence, represents the \"questions\" / \"queries\"\n",
    "        # which this particular token ask / attend to all other tokens in the sequence. HOWEVER,\n",
    "        # I believe such interpretation should apply to the matmul result above instead; Let's say\n",
    "        # the matmul result is QK (of shape (... d_q d_k)), focus on the 2-d matrix of shape (d_q d_k),\n",
    "        # then the row at index i of this matrix, whose size is d_k, represents the \"questions\" / \"queries\"\n",
    "        # of token i in the sequence to all other tokens in the same sequence. Item at index j of this\n",
    "        # row represents the query of token i to token j in the same sequence. Meanwhile, column at index i\n",
    "        # of this matrix represents the info which token at index i of sequence provides to all other tokens\n",
    "        # in the same sequence. See https://chatgpt.com/s/t_6964464a2ff48191a4208206c18b4f06\n",
    "        # In this light, we should create the mask so that the i-th token only\n",
    "        # query all its predecessor, resulting in mask matrix whose elements of lower triangular part\n",
    "        # are True while others are False\n",
    "        # Note the dimension required here is the sequence length dimension which is not available in module init time :(\n",
    "        d_seq_size = x.shape(-2)\n",
    "        mask = torch.tril(torch.ones(d_seq_size, d_seq_size, device=device, dtype=torch.bool))\n",
    "        attended_all_h: Float[Tensor, '... d_head d_seq d_embedding_per_head'] = scaled_dot_product_attention(Q_all_h, K_all_h, V_all_h, mask)\n",
    "        # Concatenate to restore the dimension of embedding vector, so that it is ready for linear transformation w/ W_O\n",
    "        attended_all_h = rearrange(attended_all_h, '... d_head d_seq d_embedding_per_head -> ... d_seq (d_head d_embedding_per_head)')\n",
    "        # output of shape (... d_seq d_model)\n",
    "        return attended_all_h @ self.W_O.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "640b0cab-7609-4099-bef4-13a17961df10",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-11T21:56:01.365251Z",
     "iopub.status.busy": "2026-01-11T21:56:01.364916Z",
     "iopub.status.idle": "2026-01-11T21:56:01.420054Z",
     "shell.execute_reply": "2026-01-11T21:56:01.416380Z",
     "shell.execute_reply.started": "2026-01-11T21:56:01.365223Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17]])\n",
      "tensor([0, 2, 4], dtype=torch.int32) tensor([2, 4, 6], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[239]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m indices = torch.arange(\u001b[32m0\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m2\u001b[39m, dtype=torch.int)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(indices, indices+\u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m:\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "# TODO Toying time: Pytorch idiomatic way to slice 2-D tensor into h pieces :D\n",
    "t = torch.arange(0, 18).reshape(3, 6)\n",
    "print(t)\n",
    "indices = torch.arange(0, 6, 2, dtype=torch.int)\n",
    "print(indices, indices+2)\n",
    "t[..., indices:indices+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ab0002b1-82ac-4591-a283-bd2853f152d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T22:45:43.656572Z",
     "iopub.status.busy": "2026-01-11T22:45:43.654781Z",
     "iopub.status.idle": "2026-01-11T22:45:43.677680Z",
     "shell.execute_reply": "2026-01-11T22:45:43.675803Z",
     "shell.execute_reply.started": "2026-01-11T22:45:43.656536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 6,  7],\n",
       "         [12, 13]],\n",
       "\n",
       "        [[ 2,  3],\n",
       "         [ 8,  9],\n",
       "         [14, 15]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [10, 11],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "# NOTE correct way of slicing\n",
    "rearrange(t, 'seq (head chunk_in_head) -> head seq chunk_in_head', head = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "20db2fcd-ecf9-4371-8d85-e7bd595d4617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T00:25:29.510204Z",
     "iopub.status.busy": "2026-01-12T00:25:29.509891Z",
     "iopub.status.idle": "2026-01-12T00:25:29.519354Z",
     "shell.execute_reply": "2026-01-12T00:25:29.517591Z",
     "shell.execute_reply.started": "2026-01-12T00:25:29.510180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask:\n",
      "tensor([[ True, False, False],\n",
      "        [ True,  True, False],\n",
      "        [ True,  True,  True]])\n",
      "target before masking:\n",
      "tensor([[[0.0000, 0.2000, 0.4000],\n",
      "         [0.6000, 0.8000, 1.0000],\n",
      "         [1.2000, 1.4000, 1.6000]],\n",
      "\n",
      "        [[1.8000, 2.0000, 2.2000],\n",
      "         [2.4000, 2.6000, 2.8000],\n",
      "         [3.0000, 3.2000, 3.4000]]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(3, 3, dtype=torch.bool))\n",
    "print(f'mask:\\n{mask}')\n",
    "\n",
    "# tensor whose values will be masked\n",
    "target = torch.arange(0, 3.6, 0.2).reshape(2, 3, 3)\n",
    "print(f'target before masking:\\n{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e01cb547-efbf-4626-851c-dacc04b4013a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T00:25:29.854501Z",
     "iopub.status.busy": "2026-01-12T00:25:29.854193Z",
     "iopub.status.idle": "2026-01-12T00:25:29.914788Z",
     "shell.execute_reply": "2026-01-12T00:25:29.912039Z",
     "shell.execute_reply.started": "2026-01-12T00:25:29.854478Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000,   -inf,   -inf],\n",
      "         [0.6000, 0.8000,   -inf],\n",
      "         [1.2000, 1.4000, 1.6000]],\n",
      "\n",
      "        [[1.8000,   -inf,   -inf],\n",
      "         [2.4000, 2.6000,   -inf],\n",
      "         [3.0000, 3.2000, 3.4000]]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [3, 3] at index 0 does not match the shape of the indexed tensor [2, 3, 3] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[264]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m target[..., ~mask] = -\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(target)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: The shape of the mask [3, 3] at index 0 does not match the shape of the indexed tensor [2, 3, 3] at index 0"
     ]
    }
   ],
   "source": [
    "# Correct; But we cannot use mask as a selector of target (aka target[mask] will fail)\n",
    "target[..., ~mask] = -float('inf')\n",
    "print(target)\n",
    "target[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "39fe6516-a878-4c1c-8f3a-666e50149813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T01:31:25.023369Z",
     "iopub.status.busy": "2026-01-12T01:31:25.020859Z",
     "iopub.status.idle": "2026-01-12T01:31:25.050232Z",
     "shell.execute_reply": "2026-01-12T01:31:25.046328Z",
     "shell.execute_reply.started": "2026-01-12T01:31:25.023335Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat along row dim:\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "repeat along col dim:\n",
      " tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "from einops import repeat\n",
    "\n",
    "t = torch.arange(0, 6).reshape(2, 3)\n",
    "print(f'repeat along row dim:\\n', repeat(t, 'row col -> (rep row) col', rep = 2))\n",
    "print(f'repeat along col dim:\\n', repeat(t, 'row col -> row (rep col)', rep = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7532c6-afd4-4df5-a80a-fde8cb8b3bc1",
   "metadata": {},
   "source": [
    "## Gauge compute resource a Transformer model of given spec is to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9c17125-ae9d-4140-8ddb-f733ec4a5dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T06:23:27.781588Z",
     "iopub.status.busy": "2026-01-18T06:23:27.781269Z",
     "iopub.status.idle": "2026-01-18T06:23:27.806881Z",
     "shell.execute_reply": "2026-01-18T06:23:27.805668Z",
     "shell.execute_reply.started": "2026-01-18T06:23:27.781563Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import prod\n",
    "import torch\n",
    "\n",
    "# Gauge result\n",
    "Result = namedtuple(\"Result\", [\"flops\", \"mem\"])\n",
    "\n",
    "\n",
    "class Gauge:\n",
    "    \"\"\"\n",
    "    Gauge the compute resource to be used by a Transformer model of given specs.\n",
    "    Supported compute resource types:\n",
    "    - FLOPs\n",
    "    - Memory usage\n",
    "\n",
    "    Assume the Transformer model being measured uses RoPE.\n",
    "\n",
    "    Calculation of memory usage is more subtle: Naive summation of memory\n",
    "    usaged in each compute component IMO doesn't make sense, as memory (either\n",
    "    machine's physical RAM or accelerator's on-device mem) got allocated and\n",
    "    released as computation comes and goes. IMO it makes more sense to measure\n",
    "    the size of data which remains in memory during forward and backward pass\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple[int, ...],\n",
    "        vocab_size: int,\n",
    "        context_len: int,\n",
    "        num_layers: int,\n",
    "        d_model: int,\n",
    "        num_heads: int,\n",
    "        d_ff: int,\n",
    "        dtype: torch.dtype | None = torch.float32,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        input_shape: Tuple representing the shape of input to Transformer\n",
    "            model. Its length represents the number of input's dimensions,\n",
    "            and its i-th item represents the size of input's i-th dimension\n",
    "            (aka number of elements *on* i-th dimension, not including\n",
    "            those in sub-dimensions). Typically (batch_size seq_len)\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.vocab_size = vocab_size\n",
    "        self.context_len = context_len\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_ff = d_ff\n",
    "        assert dtype is not None\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def trainable_params(self) -> int:\n",
    "        '''\n",
    "        Return total # trainable params of the Transformer model.\n",
    "    \n",
    "        Spec:\n",
    "            - Per Transformer block, we have 2 RMSNorms, 1 MHA and 1 FFN.\n",
    "              # params = 2 * d_model + 4 * d_model ** 2 + 3 * (d_model * d_ff)\n",
    "            - Besides Transformer blocks, we have 1 post transformer block\n",
    "              RMSNorm layer, 1 linear layer for output embedding.\n",
    "              # params = d_model + d_model * vocab_size\n",
    "            So total trainable params = num_layers * (2 * d_model + 4 * d_model ** 2\n",
    "                + 3 * (d_model * d_ff)) + d_model * (1 + vocab_size)\n",
    "        '''\n",
    "        return self.num_layers * (2 * self.d_model + 4 * self.d_model ** 2 + 3 *\n",
    "                              (self.d_model * self.d_ff)) + self.d_model * (1 + self.vocab_size)\n",
    "\n",
    "    def gauge(self) -> Result:\n",
    "        \"\"\"\n",
    "        Spec:\n",
    "\n",
    "        Assume:\n",
    "            - Operations e.g. rearrange, indexing cost no FLOPs.\n",
    "\n",
    "        Est. FLOPs required\n",
    "            = num_layer x FLOPs per transformer block +\n",
    "              1 RMSNorm over x's dims +\n",
    "              1 linear transform on x +\n",
    "              1 softmax on linear transformed result\n",
    "\n",
    "        TODO Est. memory required - Need to reconsider whether it\n",
    "        really makes sense to return mem usage in each subsequent\n",
    "        gauge_ methods.\n",
    "        \"\"\"\n",
    "        # Input embedding layer occupies memory space\n",
    "        mem_input_embedding = self.vocab_size * self.d_model * self.dtype.itemsize\n",
    "        # TODO need to account for the new tensor created from advanced indexing?\n",
    "\n",
    "        transformer_block_input_shape = (*self.input_shape, self.d_model)\n",
    "        # FLOPs and mem usage per transformer block\n",
    "        flops_block, mem_block = self.gauge_transformer_block(\n",
    "            transformer_block_input_shape,\n",
    "            self.num_heads,\n",
    "            self.d_ff,\n",
    "            self.dtype,\n",
    "        )\n",
    "        flops_norm, mem_norm = self.gauge_rms_norm(\n",
    "            transformer_block_input_shape,\n",
    "        )\n",
    "        flops_lnr, mem_lnr = self.gauge_linear(\n",
    "            transformer_block_input_shape,\n",
    "            self.vocab_size,\n",
    "            self.dtype,\n",
    "        )\n",
    "        flops_sm, mem_sm = self.gauge_softmax(\n",
    "            transformer_block_input_shape,\n",
    "            dim=-1,\n",
    "        )\n",
    "        flops_total = self.num_layers * flops_block + flops_norm + flops_lnr + flops_sm\n",
    "        mem_total = mem_input_embedding + self.num_layers * mem_block + mem_norm + mem_lnr + mem_sm\n",
    "        return Result(flops=flops_total, mem=mem_total)\n",
    "\n",
    "    def gauge_transformer_block(\n",
    "        self,\n",
    "        input_shape: tuple[int, ...],\n",
    "        num_heads: int,\n",
    "        d_ff: int,\n",
    "        dtype: torch.dtype,\n",
    "    ) -> Result:\n",
    "        \"\"\"\n",
    "        Est. FLOPs required =\n",
    "            2 RMSNorm on x's dim +\n",
    "            1 multihead attention on x's dim +\n",
    "            2 elementwise add on x's dim +\n",
    "            1 FFN on x's dim\n",
    "        \"\"\"\n",
    "        flops_norm, mem_norm = self.gauge_rms_norm(input_shape)\n",
    "        flops_mha, mem_mha = self.gauge_multihead_attention(input_shape,\n",
    "                                                            num_heads, dtype)\n",
    "        flops_ffn, mem_ffn = self.gauge_ffn(input_shape, d_ff, dtype)\n",
    "        flops_total = 2 * flops_norm + flops_mha + flops_ffn + 2 * prod(input_shape)\n",
    "        mem_total = mem_mha + mem_ffn\n",
    "        return Result(flops=flops_total, mem=mem_total)\n",
    "\n",
    "    def gauge_rms_norm(self, input_shape: tuple[int, ...]) -> Result:\n",
    "        \"\"\"\n",
    "        Est. FLOPs required =\n",
    "            1 elementwise square on x +\n",
    "            1 summation along x's last dim +\n",
    "            1 division + 1 addition + 1 sqrt on reduced x, elementwise +\n",
    "            1 mul + 1 div on x, elementwise\n",
    "        \"\"\"\n",
    "        input_size = prod(input_shape)\n",
    "        flops_sum = 0\n",
    "        # elementwise square\n",
    "        flops_sum += input_size\n",
    "        reduced_input_size = prod(input_shape[:-1])\n",
    "        # reduce by sum along input's last dim\n",
    "        flops_sum += reduced_input_size * (input_shape[-1] - 1)\n",
    "        # ops on reduced input\n",
    "        flops_sum += 3 * reduced_input_size\n",
    "        flops_sum += 2 * input_size\n",
    "        # TODO memory usage?\n",
    "        return Result(flops=flops_sum, mem=0)\n",
    "\n",
    "    def gauge_linear(self, input_shape: tuple[int, ...], d_out: int, dtype:\n",
    "                     torch.dtype) -> Result:\n",
    "        \"\"\"\n",
    "        It is more intuitive to consider first how many items there are in the\n",
    "        resultant matrix after linear transformation, then consider how many\n",
    "        ops are spent to calculate each item.\n",
    "\n",
    "        Est. FLOPs required = resultant matrix size x ([# mul ops] size of dim reduced + [# add ops] size of dim reduced - 1)\n",
    "            = prod(input's dims except last one, d_out) x (2 x size of input's last dim - 1)\n",
    "        \"\"\"\n",
    "        reduced_dim_size = input_shape[-1]\n",
    "        result_size = prod(input_shape[:-1]) * d_out\n",
    "        flops = result_size * (2 * reduced_dim_size - 1)\n",
    "\n",
    "        # numel = number of tensor elements in memory\n",
    "        # linear layer weight size\n",
    "        numel = (reduced_dim_size * d_out)\n",
    "        # resultant matrix size\n",
    "        numel += result_size * dtype.itemsize\n",
    "        return Result(flops=flops, mem=numel * dtype.itemsize)\n",
    "\n",
    "    def gauge_softmax(self, input_shape: tuple[int, ...], dim: int) -> Result:\n",
    "        \"\"\"\n",
    "        dim: Index of input dimension to apply softmax, size of this dimension\n",
    "            is `input_shape[dim]`\n",
    "\n",
    "        FLOPs estimate only applies to the naive softmax implemented here.\n",
    "\n",
    "        Est. FLOPs required =\n",
    "            1 max over x's i-th dim +\n",
    "            1 elementwise sub and exp on x's dims +\n",
    "            1 summation on x's i-th dim +\n",
    "            1 elementwise div on x's dims\n",
    "        \"\"\"\n",
    "        input_size = prod(input_shape)\n",
    "        softmaxed_dim_size = input_shape[dim]\n",
    "        # max and summation over dimension dim\n",
    "        flops = 2 * input_size / softmaxed_dim_size * (softmaxed_dim_size - 1)\n",
    "        flops += 3 * input_size\n",
    "        # TODO memory usage?\n",
    "        return Result(flops=flops, mem=0)\n",
    "\n",
    "    def gauge_multihead_attention(\n",
    "            self, input_shape: tuple[int, ...], num_heads: int, dtype:\n",
    "            torch.dtype\n",
    "    ) -> Result:\n",
    "        \"\"\"\n",
    "        Assume:\n",
    "            - d_k = k_v = d_model / num_heads\n",
    "        Est. FLOPs required (assumed application of RoPE) =\n",
    "            2 x prod(x's prefixing dims) x d_seq x 3 x d_model x d_model +\n",
    "            3 x prod(rope function input dims, aka (... 2 d_head d_seq d_embedding_per_head) ) +\n",
    "            scaled dot attention layer +\n",
    "                2 * Q.numel() * seq_len * (2 + 3/d_k)\n",
    "                = 2 * prod(... d_head d_seq d_embedding_per_head) * d_seq * (2 + 3 * h / d_model)\n",
    "            tensor stacking allocates mem and returns a new tensor +\n",
    "            matmul w/ W_O\n",
    "                2 x prod(... d_seq d_model) x d_model\n",
    "        \"\"\"\n",
    "        # batched matmul b/w x and QKV\n",
    "        d_model, d_seq = input_shape[-1], input_shape[-2]\n",
    "        input_size = prod(input_shape)\n",
    "        flops, mem = (3 * v for v in self.gauge_linear(input_shape, d_model,\n",
    "                                                       dtype))\n",
    "\n",
    "        # RoPE on Q, K\n",
    "        flops += 3 * (input_size * 2)\n",
    "        # RoPE layer precomputed angle data\n",
    "        # TODO currently we create RotaryPositionalEmbedding module for each\n",
    "        # transformer block and repeatedly compute the sin and cos of the same\n",
    "        # rotation angle. For efficient use of memory space, is there a way to\n",
    "        # share such data across multiple nn modules?\n",
    "        # Memory usage by RoPE module\n",
    "        mem += (self.context_len * d_model) * dtype.itemsize\n",
    "        # NOTE mask tensor data type = torch.bool whose element occupies 1 byte\n",
    "        mem_attn_mask = d_seq**2\n",
    "        mem += mem_attn_mask\n",
    "\n",
    "        batched_xq_dims = (\n",
    "            *input_shape[:-2],\n",
    "            self.num_heads,\n",
    "            d_seq,\n",
    "            d_model // self.num_heads,\n",
    "        )\n",
    "        flops_attn, mem_attn = self.gauge_scaled_dot_product_attention(\n",
    "            batched_xq_dims,\n",
    "            batched_xq_dims,\n",
    "            batched_xq_dims,\n",
    "            dtype,\n",
    "        )\n",
    "        flops += flops_attn\n",
    "        mem += mem_attn\n",
    "        # pytorch tensor stacking allocates and returns a new tensor of the same shape as input\n",
    "        mem += input_size * dtype.itemsize\n",
    "        # matmul w/ W_O\n",
    "        flops_outer_matmul, mem_outer_matmul = self.gauge_linear(input_shape,\n",
    "                                                                 d_model, dtype)\n",
    "        flops += flops_outer_matmul\n",
    "        mem += mem_outer_matmul\n",
    "        return Result(flops=flops, mem=mem)\n",
    "\n",
    "    def gauge_scaled_dot_product_attention(\n",
    "        self,\n",
    "        Q_shape: tuple[int, ...],\n",
    "        K_shape: tuple[int, ...],\n",
    "        V_shape: tuple[int, ...],\n",
    "        dtype: torch.dtype,\n",
    "    ) -> Result:\n",
    "        \"\"\"\n",
    "        Input of scaled_dot_product_attention function as follow:\n",
    "            Q: Float[Tensor, \"... queries d_k\"],\n",
    "            K: Float[Tensor, \"... keys d_k\"],\n",
    "            V: Float[Tensor, \"... values d_v\"],\n",
    "            mask: Bool[Tensor, \"... queries keys\"] | None = None,\n",
    "\n",
    "        Here we assume queries = keys = d_seq\n",
    "\n",
    "        Est. FLOPs required =\n",
    "            1 matmul(Q, K) +\n",
    "            1 elementwise div at dim of matmul(Q, K) +\n",
    "            1 softmax at at dim of matmul(Q, K) +\n",
    "            1 matmul(matmul(Q, K), V)\n",
    "            In practice, d_k = d_v and keys = seq_len, so reduce above to\n",
    "            following:\n",
    "            = 2 * Q.numel() * seq_len * (2 + 3/d_k)\n",
    "\n",
    "        \"\"\"\n",
    "        # batched matmul b/w Q, K\n",
    "        flops, mem = self.gauge_linear(Q_shape, K_shape[-2], dtype)\n",
    "        # NOTE gauge_linear accounts for size of linear transform weight when\n",
    "        # compute memory usage. Here however we need to discount it, as the\n",
    "        # weights have been accounted for in gauge_multihead_attention(),\n",
    "        # precisely its very 1st call to gauge_linear(). Still we need to\n",
    "        # account for the size of new matrix returned from linear transform.\n",
    "        # The same applies to below.\n",
    "        mem -= (Q_shape[-1] * K_shape[-2]) * dtype.itemsize\n",
    "        QK_shape = (*Q_shape[:-1], K_shape[-2])\n",
    "        flops_sm, mem_sm = self.gauge_softmax(QK_shape, dim=-1)\n",
    "        flops += flops_sm\n",
    "        # batched matmul b/w QK, V\n",
    "        flops_qkv, mem_qkv = self.gauge_linear(QK_shape, V_shape[-1], dtype)\n",
    "        flops += flops_qkv\n",
    "        mem_qkv -= (QK_shape[-1] * V_shape[-1]) * dtype.itemsize\n",
    "        mem += mem_qkv\n",
    "        return Result(flops=flops, mem=mem)\n",
    "\n",
    "    def gauge_ffn(self, input_shape: tuple[int, ...], d_ff: int, dtype:\n",
    "                  torch.dtype) -> Result:\n",
    "        \"\"\"\n",
    "        Est. FLOPs required =\n",
    "            matmul(x, w1) +\n",
    "            elementwise sigmoid + elementwise mul of matmul(x, w1) +\n",
    "            matmul(x, w3) +\n",
    "            elementwise mul of matmul(x, w1) +\n",
    "            matmul w/ w2\n",
    "        \"\"\"\n",
    "        d_model = input_shape[-1]\n",
    "        # matmul(x, w1) and matmul(x, w3)\n",
    "        flops, mem = (v * 2 for v in self.gauge_linear(input_shape, d_ff, dtype))\n",
    "        inner_mat_shape = (*input_shape[:-1], d_ff)\n",
    "        # elementwise sigmoid (4 ops per its math formula) and 2 mul of inner matrix\n",
    "        flops += (4 + 2) * prod(inner_mat_shape)\n",
    "        # matmul w/ w2\n",
    "        flops_outer_matmul, mem_outer_matmul = self.gauge_linear(\n",
    "            inner_mat_shape, d_model, dtype\n",
    "        )\n",
    "        flops += flops_outer_matmul\n",
    "        mem += mem_outer_matmul\n",
    "        return Result(flops, mem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07393c18-df57-4fbb-937a-8fd586a5a3f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T06:56:04.768729Z",
     "iopub.status.busy": "2026-01-18T06:56:04.768327Z",
     "iopub.status.idle": "2026-01-18T06:56:04.775120Z",
     "shell.execute_reply": "2026-01-18T06:56:04.773889Z",
     "shell.execute_reply.started": "2026-01-18T06:56:04.768686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(flops=4520375434240.0, mem=47759233536)\n",
      "Result(flops=2117771264.0, mem=541573120)\n",
      "2046646400\n"
     ]
    }
   ],
   "source": [
    "tensor_dtype = torch.float32\n",
    "\n",
    "# GPT2 XL\n",
    "g = Gauge(\n",
    "    input_shape=(1, 1024), # batch=3 seq_len=16\n",
    "    vocab_size=50257,\n",
    "    context_len=1024,\n",
    "    num_layers=48,\n",
    "    d_model=1600,\n",
    "    num_heads=25,\n",
    "    d_ff=6400,\n",
    "    dtype=tensor_dtype)\n",
    "\n",
    "print(g.gauge())\n",
    "print(g.gauge_transformer_block(input_shape=(64, 128, 128), num_heads=8, d_ff=64, dtype=tensor_dtype))\n",
    "print(g.trainable_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348c8f5-f11b-4dae-b004-2500b07e3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "g = Gauge(\n",
    "    input_shape=(1, 1024), # batch=3 seq_len=16\n",
    "    vocab_size=30000,\n",
    "    context_len=1024,\n",
    "    num_layers=48,\n",
    "    d_model=1600,\n",
    "    num_heads=25,\n",
    "    d_ff=6400,\n",
    "    dtype=tensor_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e72cef7c-d12e-427e-b034-3cfeaf98352a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T06:23:36.293768Z",
     "iopub.status.busy": "2026-01-18T06:23:36.293443Z",
     "iopub.status.idle": "2026-01-18T06:23:36.299442Z",
     "shell.execute_reply": "2026-01-18T06:23:36.297984Z",
     "shell.execute_reply.started": "2026-01-18T06:23:36.293742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2046646400"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58f4dd90-fb28-4864-aeb4-6053e1d47362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T05:49:54.902871Z",
     "iopub.status.busy": "2026-01-18T05:49:54.902567Z",
     "iopub.status.idle": "2026-01-18T05:49:54.918820Z",
     "shell.execute_reply": "2026-01-18T05:49:54.917348Z",
     "shell.execute_reply.started": "2026-01-18T05:49:54.902847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17],\n",
      "        [18, 19, 20],\n",
      "        [21, 22, 23]])\n",
      "tensor([[3, 0, 4, 6],\n",
      "        [7, 1, 6, 2]])\n",
      "tensor([[[ 9, 10, 11],\n",
      "         [ 0,  1,  2],\n",
      "         [12, 13, 14],\n",
      "         [18, 19, 20]],\n",
      "\n",
      "        [[21, 22, 23],\n",
      "         [ 3,  4,  5],\n",
      "         [18, 19, 20],\n",
      "         [ 6,  7,  8]]]) torch.Size([2, 4, 3])\n",
      "tensor([[[-1024,    10,    11],\n",
      "         [    0,     1,     2],\n",
      "         [   12,    13,    14],\n",
      "         [   18,    19,    20]],\n",
      "\n",
      "        [[   21,    22,    23],\n",
      "         [    3,     4,     5],\n",
      "         [   18,    19,    20],\n",
      "         [    6,     7,     8]]])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17],\n",
      "        [18, 19, 20],\n",
      "        [21, 22, 23]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(14)\n",
    "\n",
    "# toy input embedding tensor\n",
    "t1 = torch.arange(0, 24).reshape(8, 3)\n",
    "# batched token indices batch = 2 seq_len = 4\n",
    "indices = torch.randint(0, 8, (2, 4))\n",
    "\n",
    "print(t1)\n",
    "print(indices)\n",
    "\n",
    "selected = t1[indices]\n",
    "print(selected, selected.shape)\n",
    "\n",
    "selected[0, 0, 0] = -1024\n",
    "# this confirms selected is a newly created tensor, not a view of t1\n",
    "print(selected)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b0cb8-004c-40e4-803b-2b07f9bb66df",
   "metadata": {},
   "source": [
    "## Numpy Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bb0e6913-61c6-400b-a8de-a760cbdd7b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T21:32:35.002808Z",
     "iopub.status.busy": "2026-01-11T21:32:35.002527Z",
     "iopub.status.idle": "2026-01-11T21:32:35.011186Z",
     "shell.execute_reply": "2026-01-11T21:32:35.009875Z",
     "shell.execute_reply.started": "2026-01-11T21:32:35.002787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "4 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.arange(10)\n",
    "print(arr)\n",
    "arr.shape = (2, 5)\n",
    "print(arr)\n",
    "\n",
    "print(arr[0, 4], arr[0][4])\n",
    "\n",
    "arr.shape = (10,)\n",
    "arr[1:7:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a9ff0fb2-dec9-4b8a-955a-af98a786bdbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T21:34:42.021632Z",
     "iopub.status.busy": "2026-01-11T21:34:42.021298Z",
     "iopub.status.idle": "2026-01-11T21:34:42.029853Z",
     "shell.execute_reply": "2026-01-11T21:34:42.028539Z",
     "shell.execute_reply.started": "2026-01-11T21:34:42.021604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[::], arr[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1cdc0703-be90-4e89-90ce-f7f324a3c66a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T21:43:27.727328Z",
     "iopub.status.busy": "2026-01-11T21:43:27.726953Z",
     "iopub.status.idle": "2026-01-11T21:43:27.737573Z",
     "shell.execute_reply": "2026-01-11T21:43:27.735243Z",
     "shell.execute_reply.started": "2026-01-11T21:43:27.727301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 2) 3\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]] (2, 3)\n",
      "[[0.1 0.2 0.3]\n",
      " [0.4 0.5 0.6]] (2, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1, 0.1],[2, 0.2],[3, 0.3]], [[4, 0.4],[5, 0.5],[6, 0.6]]])\n",
    "print(x.shape, x.ndim)\n",
    "# https://numpy.org/doc/stable/user/basics.indexing.html#dimensional-indexing-tools\n",
    "print(x[..., 0], x[..., 0].shape)\n",
    "print(x[..., 1], x[..., 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a868e-2cfe-489f-b383-570166336e95",
   "metadata": {},
   "source": [
    "> (Numpy) Advanced indexing always returns a copy of the data (contrast with basic slicing that returns a view)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be019f-83c8-431a-bf6e-ca141445faa5",
   "metadata": {},
   "source": [
    "## Play matrix multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af575215-8400-493b-b7d9-e226a3bad351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:43:24.311818Z",
     "iopub.status.busy": "2026-01-15T16:43:24.311509Z",
     "iopub.status.idle": "2026-01-15T16:43:24.323376Z",
     "shell.execute_reply": "2026-01-15T16:43:24.321981Z",
     "shell.execute_reply.started": "2026-01-15T16:43:24.311790Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n",
      "tensor([[[0.0000, 0.1000, 0.2000],\n",
      "         [0.3000, 0.4000, 0.5000],\n",
      "         [0.6000, 0.7000, 0.8000]],\n",
      "\n",
      "        [[0.9000, 1.0000, 1.1000],\n",
      "         [1.2000, 1.3000, 1.4000],\n",
      "         [1.5000, 1.6000, 1.7000]],\n",
      "\n",
      "        [[1.8000, 1.9000, 2.0000],\n",
      "         [2.1000, 2.2000, 2.3000],\n",
      "         [2.4000, 2.5000, 2.6000]]])\n",
      "q = tensor([[0.0000, 0.1000, 0.2000],\n",
      "        [0.3000, 0.4000, 0.5000],\n",
      "        [0.6000, 0.7000, 0.8000]]), q shape = torch.Size([3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.5000,  1.4000,  2.3000],\n",
       "           [ 1.4000,  5.0000,  8.6000]],\n",
       " \n",
       "          [[ 3.2000,  4.1000,  5.0000],\n",
       "           [12.2000, 15.8000, 19.4000]],\n",
       " \n",
       "          [[ 5.9000,  6.8000,  7.7000],\n",
       "           [23.0000, 26.6000, 30.2000]]],\n",
       " \n",
       " \n",
       "         [[[ 2.3000,  8.6000, 14.9000],\n",
       "           [ 3.2000, 12.2000, 21.2000]],\n",
       " \n",
       "          [[21.2000, 27.5000, 33.8000],\n",
       "           [30.2000, 39.2000, 48.2000]],\n",
       " \n",
       "          [[40.1000, 46.4000, 52.7000],\n",
       "           [57.2000, 66.2000, 75.2000]]]]),\n",
       " torch.Size([2, 3, 2, 3]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from einops import einsum\n",
    "\n",
    "# (batch_size seq_len d_model)\n",
    "x = torch.arange(0, 12, 1).to(torch.float32).reshape(2, 2, 3)\n",
    "print(x)\n",
    "# spec: Use 2 tensors, one for Q,K,V and one for W_O\n",
    "# qkv of shape (3 d_model d_model)\n",
    "# q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "qkv = torch.arange(0, 2.7, 0.1).reshape(3, 3, 3)\n",
    "print(qkv)\n",
    "print(f'q = {qkv[0]}, q shape = {qkv[0].shape}')\n",
    "\n",
    "# mimic x @ W_Q.T, x @ W_K.T and x @ W_V.T in one go\n",
    "# Expect: matmul in one go: (... seq_len d_model) x (3 d_model d_model) -> (... 3 seq_len d_model)\n",
    "XQKV = einsum(x, qkv, '... seq d_model, kind d_to_split_by_head d_model -> ... kind seq d_to_split_by_head')\n",
    "XQKV, XQKV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71a6179c-c059-4183-a62a-52d684a71632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T16:55:50.755731Z",
     "iopub.status.busy": "2026-01-15T16:55:50.755369Z",
     "iopub.status.idle": "2026-01-15T16:55:50.763522Z",
     "shell.execute_reply": "2026-01-15T16:55:50.762068Z",
     "shell.execute_reply.started": "2026-01-15T16:55:50.755702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5000,  1.4000,  2.3000],\n",
      "         [ 1.4000,  5.0000,  8.6000]],\n",
      "\n",
      "        [[ 2.3000,  8.6000, 14.9000],\n",
      "         [ 3.2000, 12.2000, 21.2000]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[ 3.2000,  4.1000,  5.0000],\n",
      "         [12.2000, 15.8000, 19.4000]],\n",
      "\n",
      "        [[21.2000, 27.5000, 33.8000],\n",
      "         [30.2000, 39.2000, 48.2000]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[[ 0.5000,  1.4000,  2.3000],\n",
      "          [ 1.4000,  5.0000,  8.6000]],\n",
      "\n",
      "         [[ 3.2000,  4.1000,  5.0000],\n",
      "          [12.2000, 15.8000, 19.4000]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3000,  8.6000, 14.9000],\n",
      "          [ 3.2000, 12.2000, 21.2000]],\n",
      "\n",
      "         [[21.2000, 27.5000, 33.8000],\n",
      "          [30.2000, 39.2000, 48.2000]]]]) torch.Size([2, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# get XQ and XK\n",
    "XQ = XQKV[:, 0]\n",
    "print(XQ, XQ.shape)\n",
    "XK = XQKV[:, 1]\n",
    "print(XK, XK.shape)\n",
    "XQ_and_XK = XQKV[:, 0:2]\n",
    "print(XQ_and_XK, XQ_and_XK.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b9a5cf5-a86d-4268-a308-d9c88959815f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T17:39:34.429161Z",
     "iopub.status.busy": "2026-01-15T17:39:34.428774Z",
     "iopub.status.idle": "2026-01-15T17:39:34.435668Z",
     "shell.execute_reply": "2026-01-15T17:39:34.434594Z",
     "shell.execute_reply.started": "2026-01-15T17:39:34.429131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5000,  1.4000,  2.3000],\n",
       "          [ 1.4000,  5.0000,  8.6000]],\n",
       "\n",
       "         [[ 3.2000,  4.1000,  5.0000],\n",
       "          [12.2000, 15.8000, 19.4000]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3000,  8.6000, 14.9000],\n",
       "          [ 3.2000, 12.2000, 21.2000]],\n",
       "\n",
       "         [[21.2000, 27.5000, 33.8000],\n",
       "          [30.2000, 39.2000, 48.2000]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent to XQ_and_XK, by slicing and selecting along the 3rd-from-last dimension\n",
    "XQKV[..., 0:2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3734161-bca7-40bc-bffa-c06cf6fc7191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T17:06:36.742077Z",
     "iopub.status.busy": "2026-01-15T17:06:36.741766Z",
     "iopub.status.idle": "2026-01-15T17:06:36.747030Z",
     "shell.execute_reply": "2026-01-15T17:06:36.745598Z",
     "shell.execute_reply.started": "2026-01-15T17:06:36.742049Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function stack in module torch:\n",
      "\n",
      "stack(...)\n",
      "    stack(tensors, dim=0, *, out=None) -> Tensor\n",
      "\n",
      "    Concatenates a sequence of tensors along a new dimension.\n",
      "\n",
      "    All tensors need to be of the same size.\n",
      "\n",
      "    .. seealso::\n",
      "\n",
      "        :func:`torch.cat` concatenates the given sequence along an existing dimension.\n",
      "\n",
      "    Arguments:\n",
      "        tensors (sequence of Tensors): sequence of tensors to concatenate\n",
      "        dim (int): dimension to insert. Has to be between 0 and the number\n",
      "            of dimensions of concatenated tensors (inclusive)\n",
      "\n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352928b-2adf-443a-9548-046c7ba2161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_model.py::test_multihead_self_attention_with_rope x_even_idx shape: torch.Size([4, 4, 12, 8]) cos_by_pos shape: torch.Size([1, 1, 12, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a289499b-ad14-4b62-9fcd-43e2efcc2230",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-13T05:18:03.044296Z",
     "iopub.status.busy": "2026-01-13T05:18:03.043881Z",
     "iopub.status.idle": "2026-01-13T05:18:03.052467Z",
     "shell.execute_reply": "2026-01-13T05:18:03.050911Z",
     "shell.execute_reply.started": "2026-01-13T05:18:03.044237Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23]]) torch.Size([6, 4])\n",
      "selector tensor shape: torch.Size([2, 6])\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [12, 13, 14, 15],\n",
      "         [ 0,  1,  2,  3],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]]) torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(0, 24).reshape(6, 4)\n",
    "print(t, t.shape)\n",
    "selector = torch.tensor([[0, 1, 2, 3, 4, 5], [2, 1, 3, 0, 4, 5]])\n",
    "print(f'selector tensor shape: {selector.shape}')\n",
    "ts = t[selector]\n",
    "print(ts, ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06181cfc-45fc-40e2-8d4e-3809df422b8c",
   "metadata": {},
   "source": [
    "## Test nn.Module w/ multi-return values from its `forward()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f48a9f01-47b2-469b-bf44-df5cfb081f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T05:38:24.634611Z",
     "iopub.status.busy": "2026-01-14T05:38:24.634303Z",
     "iopub.status.idle": "2026-01-14T05:38:24.646837Z",
     "shell.execute_reply": "2026-01-14T05:38:24.644694Z",
     "shell.execute_reply.started": "2026-01-14T05:38:24.634586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy1: x = tensor([9, 8, 7])\n",
      "Toy2: x = (tensor([9, 8, 7]), tensor([1, 2, 3])) pos = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Toy1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'Toy1: x = {x}')\n",
    "        return x, torch.tensor([1, 2, 3])\n",
    "\n",
    "class Toy2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x, pos = None):\n",
    "        print(f'Toy2: x = {x} pos = {pos}')\n",
    "        return torch.zeros(2, 2)\n",
    "\n",
    "\n",
    "toy_seq = nn.Sequential(Toy1(), Toy2())\n",
    "toy_seq(torch.tensor([9, 8, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d82e38-e408-42f7-83d4-5891a3ad6216",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-14T05:42:08.849424Z",
     "iopub.status.busy": "2026-01-14T05:42:08.849118Z",
     "iopub.status.idle": "2026-01-14T05:42:08.960946Z",
     "shell.execute_reply": "2026-01-14T05:42:08.959918Z",
     "shell.execute_reply.started": "2026-01-14T05:42:08.849400Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m toy_module_list = nn.ModuleList([Toy1(), Toy2()])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtoy_module_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/stanford.cs336/assignment1-basics/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/stanford.cs336/assignment1-basics/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/stanford.cs336/assignment1-basics/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:374\u001b[39m, in \u001b[36m_forward_unimplemented\u001b[39m\u001b[34m(self, *input)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, *\u001b[38;5;28minput\u001b[39m: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    364\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[32m    365\u001b[39m \n\u001b[32m    366\u001b[39m \u001b[33;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m \u001b[33;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m function\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "toy_module_list = nn.ModuleList([Toy1(), Toy2()])\n",
    "toy_module_list(torch.tensor([9, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "295fd961-f2b8-4294-b9b1-90ba01a71090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T19:05:20.064746Z",
     "iopub.status.busy": "2026-01-17T19:05:20.064432Z",
     "iopub.status.idle": "2026-01-17T19:05:20.070764Z",
     "shell.execute_reply": "2026-01-17T19:05:20.069272Z",
     "shell.execute_reply.started": "2026-01-17T19:05:20.064721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n",
      "(1, 2)\n",
      "(1, 2, 3, 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "t1 = (1, 2)\n",
    "t2 = (*t1, 3)\n",
    "print(t2)\n",
    "print(t2[:-1])\n",
    "print(2 * t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebf90bf5-b062-40b0-a888-1c08fc5eb818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T18:21:15.117638Z",
     "iopub.status.busy": "2026-01-17T18:21:15.117329Z",
     "iopub.status.idle": "2026-01-17T18:21:15.130828Z",
     "shell.execute_reply": "2026-01-17T18:21:15.129242Z",
     "shell.execute_reply.started": "2026-01-17T18:21:15.117613Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.1000, 0.2000],\n",
      "         [0.3000, 0.4000, 0.5000]],\n",
      "\n",
      "        [[0.6000, 0.7000, 0.8000],\n",
      "         [0.9000, 1.0000, 1.1000]],\n",
      "\n",
      "        [[1.2000, 1.3000, 1.4000],\n",
      "         [1.5000, 1.6000, 1.7000]],\n",
      "\n",
      "        [[1.8000, 1.9000, 2.0000],\n",
      "         [2.1000, 2.2000, 2.3000]]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[[ 1.3000,  1.6000],\n",
      "         [ 4.0000,  5.2000]],\n",
      "\n",
      "        [[ 6.7000,  8.8000],\n",
      "         [ 9.4000, 12.4000]],\n",
      "\n",
      "        [[12.1000, 16.0000],\n",
      "         [14.8000, 19.6000]],\n",
      "\n",
      "        [[17.5000, 23.2000],\n",
      "         [20.2000, 26.8000]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.arange(0, 2.4, 0.1).reshape(4, 2, 3)\n",
    "t2 = torch.arange(1, 7, 1).to(torch.float32).reshape(3, 2)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t1 @ t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6063690a-020b-47e7-8dad-1c6bc50d4610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T22:24:32.331031Z",
     "iopub.status.busy": "2026-01-17T22:24:32.328010Z",
     "iopub.status.idle": "2026-01-17T22:24:32.355945Z",
     "shell.execute_reply": "2026-01-17T22:24:32.352056Z",
     "shell.execute_reply.started": "2026-01-17T22:24:32.330901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bool.itemsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab1c8e-52ac-4e56-a2f5-a4749c0a8fbf",
   "metadata": {},
   "source": [
    "## Pytorch tensor stacking allocates mem and returns a new tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03acc5ee-56fc-4ef8-b2b4-156564f18e12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T22:30:18.881120Z",
     "iopub.status.busy": "2026-01-17T22:30:18.880813Z",
     "iopub.status.idle": "2026-01-17T22:30:18.888426Z",
     "shell.execute_reply": "2026-01-17T22:30:18.887240Z",
     "shell.execute_reply.started": "2026-01-17T22:30:18.881094Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "tensor([[-100,    1,    2],\n",
      "        [   3,    4,    5]])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t1 = torch.arange(0, 6).reshape(2, 3)\n",
    "t2 = torch.arange(6, 12).reshape(2, 3)\n",
    "\n",
    "t3 = torch.stack([t1, t2])\n",
    "print(t3)\n",
    "\n",
    "t1[0, 0] = -100\n",
    "print(t1)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298deec-138d-4e2b-a792-5d37ebb69fec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scratch: Pytorch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9985dd7-4007-4226-9d3d-79d793639630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T04:51:20.118470Z",
     "iopub.status.busy": "2026-01-03T04:51:20.112752Z",
     "iopub.status.idle": "2026-01-03T04:51:20.607295Z",
     "shell.execute_reply": "2026-01-03T04:51:20.605631Z",
     "shell.execute_reply.started": "2026-01-03T04:51:20.117975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 936.250643272073\n",
      "199 645.6479100440048\n",
      "299 446.59769261270117\n",
      "399 310.1005226218571\n",
      "499 216.39180309800014\n",
      "599 151.98552907638506\n",
      "699 107.66922492043156\n",
      "799 77.14248585274315\n",
      "899 56.091513441801744\n",
      "999 41.55931924194568\n",
      "1099 31.516652391540806\n",
      "1199 24.569345205417985\n",
      "1299 19.75847589733717\n",
      "1399 16.423754124106054\n",
      "1499 14.110020007413638\n",
      "1599 12.50317712048318\n",
      "1699 11.386243389773334\n",
      "1799 10.609168273305954\n",
      "1899 10.068080749363528\n",
      "1999 9.691005440031622\n",
      "Result: y = -0.028238700554603 + 0.8443640706625123 x + 0.004871645739674506 x^2 + -0.09156990094297779 x^3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21c25ae8-e224-4ba3-bf70-e4d996f68699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T05:52:43.577042Z",
     "iopub.status.busy": "2026-01-03T05:52:43.571218Z",
     "iopub.status.idle": "2026-01-03T05:53:15.640345Z",
     "shell.execute_reply": "2026-01-03T05:53:15.638915Z",
     "shell.execute_reply.started": "2026-01-03T05:52:43.576887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration t =   99  loss(t)/loss(0) =   0.358655  a =   0.675835  b =   0.660643  c =   1.421510  d =   0.588552\n",
      "Iteration t =  199  loss(t)/loss(0) =   0.192731  a =   0.763050  b =   0.725041  c =   1.180236  d =   0.589011\n",
      "Iteration t =  299  loss(t)/loss(0) =   0.108448  a =   0.826638  b =   0.749254  c =   1.004798  d =   0.566660\n",
      "Iteration t =  399  loss(t)/loss(0) =   0.063148  a =   0.872891  b =   0.766290  c =   0.877192  d =   0.542195\n",
      "Iteration t =  499  loss(t)/loss(0) =   0.038468  a =   0.906533  b =   0.781354  c =   0.784376  d =   0.518750\n",
      "Iteration t =  599  loss(t)/loss(0) =   0.024785  a =   0.931004  b =   0.795313  c =   0.716866  d =   0.496726\n",
      "Iteration t =  699  loss(t)/loss(0) =   0.016996  a =   0.948802  b =   0.808353  c =   0.667761  d =   0.476106\n",
      "Iteration t =  799  loss(t)/loss(0) =   0.012395  a =   0.961748  b =   0.820550  c =   0.632045  d =   0.456811\n",
      "Iteration t =  899  loss(t)/loss(0) =   0.009540  a =   0.971165  b =   0.831962  c =   0.606066  d =   0.438756\n",
      "Iteration t =  999  loss(t)/loss(0) =   0.007662  a =   0.978014  b =   0.842640  c =   0.587170  d =   0.421863\n",
      "Iteration t = 1099  loss(t)/loss(0) =   0.006345  a =   0.982996  b =   0.852631  c =   0.573426  d =   0.406056\n",
      "Iteration t = 1199  loss(t)/loss(0) =   0.005366  a =   0.986619  b =   0.861979  c =   0.563429  d =   0.391266\n",
      "Iteration t = 1299  loss(t)/loss(0) =   0.004601  a =   0.989255  b =   0.870726  c =   0.556158  d =   0.377428\n",
      "Iteration t = 1399  loss(t)/loss(0) =   0.003980  a =   0.991172  b =   0.878910  c =   0.550869  d =   0.364480\n",
      "Iteration t = 1499  loss(t)/loss(0) =   0.003462  a =   0.992567  b =   0.886568  c =   0.547022  d =   0.352365\n",
      "Iteration t = 1599  loss(t)/loss(0) =   0.003022  a =   0.993581  b =   0.893733  c =   0.544224  d =   0.341029\n",
      "Iteration t = 1699  loss(t)/loss(0) =   0.002644  a =   0.994318  b =   0.900437  c =   0.542189  d =   0.330423\n",
      "Iteration t = 1799  loss(t)/loss(0) =   0.002317  a =   0.994855  b =   0.906710  c =   0.540708  d =   0.320498\n",
      "Iteration t = 1899  loss(t)/loss(0) =   0.002033  a =   0.995245  b =   0.912580  c =   0.539632  d =   0.311212\n",
      "Iteration t = 1999  loss(t)/loss(0) =   0.001785  a =   0.995529  b =   0.918072  c =   0.538849  d =   0.302524\n",
      "Iteration t = 2099  loss(t)/loss(0) =   0.001569  a =   0.995736  b =   0.923210  c =   0.538279  d =   0.294394\n",
      "Iteration t = 2199  loss(t)/loss(0) =   0.001380  a =   0.995886  b =   0.928018  c =   0.537865  d =   0.286788\n",
      "Iteration t = 2299  loss(t)/loss(0) =   0.001214  a =   0.995995  b =   0.932517  c =   0.537563  d =   0.279670\n",
      "Iteration t = 2399  loss(t)/loss(0) =   0.001069  a =   0.996074  b =   0.936726  c =   0.537344  d =   0.273011\n",
      "Iteration t = 2499  loss(t)/loss(0) =   0.000943  a =   0.996132  b =   0.940665  c =   0.537185  d =   0.266780\n",
      "Iteration t = 2599  loss(t)/loss(0) =   0.000832  a =   0.996174  b =   0.944350  c =   0.537069  d =   0.260950\n",
      "Iteration t = 2699  loss(t)/loss(0) =   0.000735  a =   0.996204  b =   0.947798  c =   0.536985  d =   0.255495\n",
      "Iteration t = 2799  loss(t)/loss(0) =   0.000650  a =   0.996226  b =   0.951024  c =   0.536924  d =   0.250390\n",
      "Iteration t = 2899  loss(t)/loss(0) =   0.000575  a =   0.996243  b =   0.954043  c =   0.536879  d =   0.245614\n",
      "Iteration t = 2999  loss(t)/loss(0) =   0.000510  a =   0.996255  b =   0.956868  c =   0.536847  d =   0.241146\n",
      "Iteration t = 3099  loss(t)/loss(0) =   0.000453  a =   0.996263  b =   0.959510  c =   0.536823  d =   0.236965\n",
      "Iteration t = 3199  loss(t)/loss(0) =   0.000403  a =   0.996269  b =   0.961983  c =   0.536807  d =   0.233052\n",
      "Iteration t = 3299  loss(t)/loss(0) =   0.000359  a =   0.996274  b =   0.964297  c =   0.536795  d =   0.229392\n",
      "Iteration t = 3399  loss(t)/loss(0) =   0.000321  a =   0.996277  b =   0.966462  c =   0.536785  d =   0.225967\n",
      "Iteration t = 3499  loss(t)/loss(0) =   0.000288  a =   0.996279  b =   0.968488  c =   0.536779  d =   0.222762\n",
      "Iteration t = 3599  loss(t)/loss(0) =   0.000258  a =   0.996281  b =   0.970383  c =   0.536773  d =   0.219763\n",
      "Iteration t = 3699  loss(t)/loss(0) =   0.000233  a =   0.996282  b =   0.972156  c =   0.536770  d =   0.216958\n",
      "Iteration t = 3799  loss(t)/loss(0) =   0.000210  a =   0.996282  b =   0.973816  c =   0.536770  d =   0.214332\n",
      "Iteration t = 3899  loss(t)/loss(0) =   0.000191  a =   0.996282  b =   0.975368  c =   0.536770  d =   0.211876\n",
      "Iteration t = 3999  loss(t)/loss(0) =   0.000173  a =   0.996282  b =   0.976821  c =   0.536770  d =   0.209578\n",
      "Iteration t = 4099  loss(t)/loss(0) =   0.000158  a =   0.996282  b =   0.978180  c =   0.536770  d =   0.207427\n",
      "Iteration t = 4199  loss(t)/loss(0) =   0.000145  a =   0.996282  b =   0.979452  c =   0.536770  d =   0.205415\n",
      "Iteration t = 4299  loss(t)/loss(0) =   0.000133  a =   0.996282  b =   0.980642  c =   0.536770  d =   0.203533\n",
      "Iteration t = 4399  loss(t)/loss(0) =   0.000123  a =   0.996282  b =   0.981755  c =   0.536770  d =   0.201771\n",
      "Iteration t = 4499  loss(t)/loss(0) =   0.000114  a =   0.996282  b =   0.982797  c =   0.536770  d =   0.200123\n",
      "Iteration t = 4599  loss(t)/loss(0) =   0.000107  a =   0.996282  b =   0.983772  c =   0.536770  d =   0.198581\n",
      "Iteration t = 4699  loss(t)/loss(0) =   0.000100  a =   0.996282  b =   0.984684  c =   0.536770  d =   0.197138\n",
      "Iteration t = 4799  loss(t)/loss(0) =   0.000094  a =   0.996282  b =   0.985538  c =   0.536770  d =   0.195787\n",
      "Iteration t = 4899  loss(t)/loss(0) =   0.000089  a =   0.996282  b =   0.986336  c =   0.536770  d =   0.194524\n",
      "Iteration t = 4999  loss(t)/loss(0) =   0.000084  a =   0.996282  b =   0.987083  c =   0.536770  d =   0.193342\n",
      "Result: y = 0.9962821006774902 + 0.9870904684066772 x + 0.5367701649665833 x^2 + 0.19333051145076752 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# We want to be able to train our model on an `accelerator <https://pytorch.org/docs/stable/torch.html#accelerators>`__\n",
    "# such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU.\n",
    "\n",
    "dtype = torch.float\n",
    "#device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "#print(f\"Using {device} device\")\n",
    "# Surprisingly my old MBP still has MPS support:\n",
    "# https://developer.apple.com/metal/pytorch/\n",
    "torch.set_default_device('mps')\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "x = torch.linspace(-1, 1, 2000, dtype=dtype)\n",
    "y = torch.exp(x) # A Taylor expansion would be 1 + x + (1/2) x**2 + (1/3!) x**3 + ...\n",
    "\n",
    "# Create random Tensors for weights. For a third order polynomial, we need\n",
    "# 4 weights: y = a + b x + c x^2 + d x^3\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "\n",
    "initial_loss = 1.\n",
    "learning_rate = 1e-5\n",
    "for t in range(5000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "\n",
    "    # Calculare initial loss, so we can report loss relative to it\n",
    "    if t==0:\n",
    "        initial_loss=loss.item()\n",
    "\n",
    "    if t % 100 == 99:\n",
    "        print(f'Iteration t = {t:4d}  loss(t)/loss(0) = {round(loss.item()/initial_loss, 6):10.6f}  a = {a.item():10.6f}  b = {b.item():10.6f}  c = {c.item():10.6f}  d = {d.item():10.6f}')\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9feaf88b-e021-47fd-9b30-714016bc99e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T06:43:28.533592Z",
     "iopub.status.busy": "2026-01-03T06:43:28.531108Z",
     "iopub.status.idle": "2026-01-03T06:43:28.885832Z",
     "shell.execute_reply": "2026-01-03T06:43:28.884292Z",
     "shell.execute_reply.started": "2026-01-03T06:43:28.533506Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "686c5462-38b9-4fc5-a236-47e72d062f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T06:43:42.389302Z",
     "iopub.status.busy": "2026-01-03T06:43:42.388946Z",
     "iopub.status.idle": "2026-01-03T06:43:42.415270Z",
     "shell.execute_reply": "2026-01-03T06:43:42.414224Z",
     "shell.execute_reply.started": "2026-01-03T06:43:42.389275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ccbbf63-9e8b-45fc-a30f-89093c6206e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:45:26.770102Z",
     "iopub.status.busy": "2026-01-06T16:45:26.769589Z",
     "iopub.status.idle": "2026-01-06T16:45:27.068377Z",
     "shell.execute_reply": "2026-01-06T16:45:27.065788Z",
     "shell.execute_reply.started": "2026-01-06T16:45:26.770047Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.RandomState(42).normal(size=[10, 32, 100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7a5a19b-0b72-4668-93cc-a358f64c11c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:56:18.703360Z",
     "iopub.status.busy": "2026-01-06T16:56:18.703096Z",
     "iopub.status.idle": "2026-01-06T16:56:18.751714Z",
     "shell.execute_reply": "2026-01-06T16:56:18.746912Z",
     "shell.execute_reply.started": "2026-01-06T16:56:18.703339Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 100, 200)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_listed = list(x)\n",
    "rearrange(x_listed, 'b c h w -> b c h w').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08f76804-dad4-4aa6-97bc-6d71c8e9167c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:57:17.949113Z",
     "iopub.status.busy": "2026-01-06T16:57:17.948806Z",
     "iopub.status.idle": "2026-01-06T16:57:17.958371Z",
     "shell.execute_reply": "2026-01-06T16:57:17.956316Z",
     "shell.execute_reply.started": "2026-01-06T16:57:17.949089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "tensors = list([\n",
    "    torch.tensor([[1, 2], [3,4]]),\n",
    "    torch.tensor([[5, 6], [7, 8]]),\n",
    "])\n",
    "rearrange(tensors, 'i j k -> i j k').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37bbb8bd-d6de-431f-8473-43eb5b9eb024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:37:13.348131Z",
     "iopub.status.busy": "2026-01-06T17:37:13.347876Z",
     "iopub.status.idle": "2026-01-06T17:37:13.355054Z",
     "shell.execute_reply": "2026-01-06T17:37:13.353879Z",
     "shell.execute_reply.started": "2026-01-06T17:37:13.348110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9269,  1.4873],\n",
       "         [ 0.9007, -2.1055],\n",
       "         [ 0.6784, -1.2345],\n",
       "         [-0.0431, -1.6047]],\n",
       "\n",
       "        [[ 0.3559, -0.6866],\n",
       "         [-0.4934,  0.2415],\n",
       "         [-1.1109,  0.0915],\n",
       "         [-2.3169, -0.2168]],\n",
       "\n",
       "        [[-0.3097, -0.3957],\n",
       "         [ 0.8034, -0.6216],\n",
       "         [-0.5920, -0.0631],\n",
       "         [-0.8286,  0.3309]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size, seq_len, embedding\n",
    "torch.manual_seed(42)\n",
    "token_embeddings = torch.randn(3, 4, 2)\n",
    "token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a255854-d0ae-41f2-956e-ed88b6cdb1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:48:03.064623Z",
     "iopub.status.busy": "2026-01-06T17:48:03.064326Z",
     "iopub.status.idle": "2026-01-06T17:48:03.071335Z",
     "shell.execute_reply": "2026-01-06T17:48:03.070491Z",
     "shell.execute_reply.started": "2026-01-06T17:48:03.064598Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.1000, 0.0000],\n",
       "         [0.0000, 0.1000]],\n",
       "\n",
       "        [[0.2000, 0.0000],\n",
       "         [0.0000, 0.2000]],\n",
       "\n",
       "        [[0.3000, 0.0000],\n",
       "         [0.0000, 0.3000]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos, d_embedding, d_embedding\n",
    "dummy_rotation_mat = rearrange([torch.eye(2) * i * 0.1 for i in range(4)], '... -> ...')\n",
    "dummy_rotation_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9505f81c-46a1-4366-b8b2-252661b4b2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:48:04.050639Z",
     "iopub.status.busy": "2026-01-06T17:48:04.050308Z",
     "iopub.status.idle": "2026-01-06T17:48:04.060284Z",
     "shell.execute_reply": "2026-01-06T17:48:04.059099Z",
     "shell.execute_reply.started": "2026-01-06T17:48:04.050617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 0, 2],\n",
       "        [2, 3, 0, 0],\n",
       "        [2, 1, 2, 2]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch, seq_len\n",
    "torch.manual_seed(42)\n",
    "token_positions = torch.randint(low=0, high=4, size=(3, 4))\n",
    "token_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c64ada9-2e72-42ca-bc4d-2c6334eb2e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:49:08.283751Z",
     "iopub.status.busy": "2026-01-06T17:49:08.283449Z",
     "iopub.status.idle": "2026-01-06T17:49:08.293464Z",
     "shell.execute_reply": "2026-01-06T17:49:08.291730Z",
     "shell.execute_reply.started": "2026-01-06T17:49:08.283727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2000, 0.0000],\n",
       "          [0.0000, 0.2000]],\n",
       "\n",
       "         [[0.3000, 0.0000],\n",
       "          [0.0000, 0.3000]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         [[0.2000, 0.0000],\n",
       "          [0.0000, 0.2000]]],\n",
       "\n",
       "\n",
       "        [[[0.2000, 0.0000],\n",
       "          [0.0000, 0.2000]],\n",
       "\n",
       "         [[0.3000, 0.0000],\n",
       "          [0.0000, 0.3000]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.2000, 0.0000],\n",
       "          [0.0000, 0.2000]],\n",
       "\n",
       "         [[0.1000, 0.0000],\n",
       "          [0.0000, 0.1000]],\n",
       "\n",
       "         [[0.2000, 0.0000],\n",
       "          [0.0000, 0.2000]],\n",
       "\n",
       "         [[0.2000, 0.0000],\n",
       "          [0.0000, 0.2000]]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_rotation_mats = dummy_rotation_mat[token_positions]\n",
    "selected_rotation_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd92efca-06bf-4432-80b8-826a9e96b2f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T18:00:53.629323Z",
     "iopub.status.busy": "2026-01-06T18:00:53.629006Z",
     "iopub.status.idle": "2026-01-06T18:00:53.639609Z",
     "shell.execute_reply": "2026-01-06T18:00:53.637641Z",
     "shell.execute_reply.started": "2026-01-06T18:00:53.629297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3854,  0.2975],\n",
       "         [ 0.2702, -0.6317],\n",
       "         [ 0.0000, -0.0000],\n",
       "         [-0.0086, -0.3209]],\n",
       "\n",
       "        [[ 0.0712, -0.1373],\n",
       "         [-0.1480,  0.0724],\n",
       "         [-0.0000,  0.0000],\n",
       "         [-0.0000, -0.0000]],\n",
       "\n",
       "        [[-0.0619, -0.0791],\n",
       "         [ 0.0803, -0.0622],\n",
       "         [-0.1184, -0.0126],\n",
       "         [-0.1657,  0.0662]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import einsum\n",
    "\n",
    "einsum(token_embeddings, selected_rotation_mats, '... d_k, ... d_k d_k -> ... d_k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19311bd2-4535-4960-84e6-8122ae7b039a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T23:56:34.268483Z",
     "iopub.status.busy": "2026-01-06T23:56:34.258820Z",
     "iopub.status.idle": "2026-01-06T23:56:34.335487Z",
     "shell.execute_reply": "2026-01-06T23:56:34.331567Z",
     "shell.execute_reply.started": "2026-01-06T23:56:34.268388Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function arange in module torch:\n",
      "\n",
      "arange(...)\n",
      "    arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "\n",
      "    Returns a 1-D tensor of size :math:`\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil`\n",
      "    with values from the interval ``[start, end)`` taken with common difference\n",
      "    :attr:`step` beginning from `start`.\n",
      "\n",
      "    Note that non-integer :attr:`step` is subject to floating point rounding errors when\n",
      "    comparing against :attr:`end`; to avoid inconsistency, we advise subtracting a small epsilon from :attr:`end`\n",
      "    in such cases.\n",
      "\n",
      "    .. math::\n",
      "        \\text{out}_{{i+1}} = \\text{out}_{i} + \\text{step}\n",
      "\n",
      "    Args:\n",
      "        start (Number): the starting value for the set of points. Default: ``0``.\n",
      "        end (Number): the ending value for the set of points\n",
      "        step (Number): the gap between each pair of adjacent points. Default: ``1``.\n",
      "\n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_dtype`). If `dtype` is not given, infer the data type from the other input\n",
      "            arguments. If any of `start`, `end`, or `stop` are floating-point, the\n",
      "            `dtype` is inferred to be the default dtype, see\n",
      "            :meth:`~torch.get_default_dtype`. Otherwise, the `dtype` is inferred to\n",
      "            be `torch.int64`.\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_device`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "\n",
      "    Example::\n",
      "\n",
      "        >>> torch.arange(5)\n",
      "        tensor([ 0,  1,  2,  3,  4])\n",
      "        >>> torch.arange(1, 4)\n",
      "        tensor([ 1,  2,  3])\n",
      "        >>> torch.arange(1, 2.5, 0.5)\n",
      "        tensor([ 1.0000,  1.5000,  2.0000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.arange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3291becf-e7ce-43e3-9f7a-9997f16c1d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T23:57:10.308302Z",
     "iopub.status.busy": "2026-01-06T23:57:10.307979Z",
     "iopub.status.idle": "2026-01-06T23:57:10.352492Z",
     "shell.execute_reply": "2026-01-06T23:57:10.351047Z",
     "shell.execute_reply.started": "2026-01-06T23:57:10.308278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n",
       "        0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700,\n",
       "        0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600,\n",
       "        0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500,\n",
       "        0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400,\n",
       "        0.4500, 0.4600, 0.4700, 0.4800, 0.4900])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 0.5, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ee9ebaee-1b00-4a89-9048-8adc387435ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T23:59:18.781804Z",
     "iopub.status.busy": "2026-01-06T23:59:18.781441Z",
     "iopub.status.idle": "2026-01-06T23:59:18.792733Z",
     "shell.execute_reply": "2026-01-06T23:59:18.791569Z",
     "shell.execute_reply.started": "2026-01-06T23:59:18.781776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = 4\n",
    "positions = torch.arange(max_seq_len)\n",
    "print(f'positions = {positions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e38f17a0-e5db-4bf6-b9bf-f2a213c1360c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T00:18:24.258991Z",
     "iopub.status.busy": "2026-01-07T00:18:24.258642Z",
     "iopub.status.idle": "2026-01-07T00:18:24.271270Z",
     "shell.execute_reply": "2026-01-07T00:18:24.269764Z",
     "shell.execute_reply.started": "2026-01-07T00:18:24.258965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c0fed767-a894-4fda-84bd-a787b6a254bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T00:19:53.230410Z",
     "iopub.status.busy": "2026-01-07T00:19:53.230085Z",
     "iopub.status.idle": "2026-01-07T00:19:53.241486Z",
     "shell.execute_reply": "2026-01-07T00:19:53.240001Z",
     "shell.execute_reply.started": "2026-01-07T00:19:53.230384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_exps = tensor([1.0000, 1.2407, 1.5393])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.2407, 1.5393],\n",
       "        [2.0000, 2.4814, 3.0787],\n",
       "        [3.0000, 3.7221, 4.6180]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = torch.pi / 6\n",
    "\n",
    "d_k = 6\n",
    "# torch.arange(0, d_k, 2) enumerates all values of 2k-2 for k in [1, d_k/2]\n",
    "exponents = torch.arange(0, d_k, 2) / d_k\n",
    "# 1 / (theta^((2k-2)/d))\n",
    "inv_exps = theta ** -exponents\n",
    "print(f'inv_exps = {inv_exps}')\n",
    "\n",
    "# shape (max_seq_len, 1) x shape (1, d_k/2). Here is (4, 1) x (1, 3) works by broadcasting\n",
    "angles = positions[:, None] * inv_exps[None, :]\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "50c92416-7519-405d-914f-a30f1dfcacf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T00:23:58.482211Z",
     "iopub.status.busy": "2026-01-07T00:23:58.481876Z",
     "iopub.status.idle": "2026-01-07T00:23:58.493861Z",
     "shell.execute_reply": "2026-01-07T00:23:58.492504Z",
     "shell.execute_reply.started": "2026-01-07T00:23:58.482183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "        [ 0.5403,  0.3241,  0.0315],\n",
       "        [-0.4161, -0.7899, -0.9980],\n",
       "        [-0.9900, -0.8362, -0.0942]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin, cos = torch.sin(angles), torch.cos(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "69bbd63f-ac2d-47dc-845c-9839b7981aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T00:28:17.285147Z",
     "iopub.status.busy": "2026-01-07T00:28:17.284775Z",
     "iopub.status.idle": "2026-01-07T00:28:17.313058Z",
     "shell.execute_reply": "2026-01-07T00:28:17.311514Z",
     "shell.execute_reply.started": "2026-01-07T00:28:17.285115Z"
    }
   },
   "outputs": [],
   "source": [
    "R = torch.zeros(max_seq_len, d_k, d_k)\n",
    "# Fill 22 blocks\n",
    "idx = torch.arange(0, d_k, 2)\n",
    "R[:, idx, idx] = cos\n",
    "R[:, idx, idx + 1] = -sin\n",
    "R[:, idx + 1, idx] = sin\n",
    "R[:, idx + 1, idx + 1] = cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "68bbecd8-ae5e-4f59-bb05-da0a6aa90e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T00:28:19.323750Z",
     "iopub.status.busy": "2026-01-07T00:28:19.323438Z",
     "iopub.status.idle": "2026-01-07T00:28:19.333736Z",
     "shell.execute_reply": "2026-01-07T00:28:19.332531Z",
     "shell.execute_reply.started": "2026-01-07T00:28:19.323725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  1.0000, -0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  1.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.5403, -0.8415,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.8415,  0.5403,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.3241, -0.9460,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.9460,  0.3241,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0315, -0.9995],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.9995,  0.0315]],\n",
       "\n",
       "        [[-0.4161, -0.9093,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.9093, -0.4161,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.7899, -0.6133,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.6133, -0.7899,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.9980, -0.0629],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0629, -0.9980]],\n",
       "\n",
       "        [[-0.9900, -0.1411,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1411, -0.9900,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.8362,  0.5485,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -0.5485, -0.8362,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0942,  0.9956],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.9956, -0.0942]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d17977-8a62-4a24-8794-89417a1fa79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
